{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 21:35:22.964341: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-08 21:35:23.084789: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-08 21:35:23.090534: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-12-08 21:35:23.090550: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-12-08 21:35:23.120120: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-08 21:35:29.080950: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-12-08 21:35:29.081053: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-12-08 21:35:29.081061: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, Dense, Concatenate, TimeDistributed, LSTM, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from helper_funcs import gen_samples\n",
    "from scipy.fft import rfftfreq\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First navigate to our directory\n",
    "transfer_directory_path = os.path.join(\"Data\", \"synth_transfer_df.parquet\")\n",
    "general_directory_path = os.path.join(\"Data\", \"synth_general_df.parquet\")\n",
    "# Load the dataframes\n",
    "synth_transfer_df = pd.read_parquet(transfer_directory_path)\n",
    "synth_general_df = pd.read_parquet(general_directory_path)\n",
    "# Concatenate (after making sure they share columns) and then reset indices\n",
    "assert list(synth_transfer_df.columns) == list(synth_general_df.columns), \"Column names do not match!\"\n",
    "df = pd.concat([synth_transfer_df, synth_general_df], axis=0)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train (70%) and temp (30%) with stratification\n",
    "train_df, temp_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.3,\n",
    "    stratify=df['species'],  # Stratify based on the 'species' column\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split temp into test (15%) and validation (15%)\n",
    "test_df, val_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_df['species'],  # Stratify again to maintain balance\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Training Samples\n",
      "Generating Test Samples\n",
      "Generating Validation Samples\n"
     ]
    }
   ],
   "source": [
    "# Prepare samples\n",
    "print(\"Generating Training Samples\")\n",
    "X_train, y_train, mins_maxes_train, isolated_peaks_train = gen_samples(train_df)\n",
    "print(\"Generating Test Samples\")\n",
    "X_test, y_test, mins_maxes_test, isolated_peaks_test = gen_samples(test_df)\n",
    "print(\"Generating Validation Samples\")\n",
    "X_val, y_val, mins_maxes_val, isolated_peaks_val = gen_samples(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_func(snr, k=3):\n",
    "    return ((snr/k)**k) / (1 + (snr/k)**k)\n",
    "\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom loss function for (batch_size, N, 3):\n",
    "    - Binary cross-entropy for the first output node.\n",
    "    - MSE for the second and third output nodes, masked by the first node's true labels.\n",
    "    - Each bin in each sample is weighted by f(SNR), where SNR is the 3rd node label.\n",
    "    \n",
    "    Args:\n",
    "    y_true: Tensor of true labels, shape (batch_size, N, 3).\n",
    "    y_pred: Tensor of predicted values, shape (batch_size, N, 3).\n",
    "    \n",
    "    Returns:\n",
    "    A scalar tensor representing the combined loss.\n",
    "    \"\"\"\n",
    "\n",
    "    # Mean squared error for the second and third nodes\n",
    "    mse_loss_2 = tf.square(y_true[..., 1] - y_pred[..., 1])\n",
    "    mse_loss_3 = tf.square(y_true[..., 2] - y_pred[..., 2])\n",
    "    mse_loss = mse_loss_2 + mse_loss_3  # Shape (batch_size, N)\n",
    "\n",
    "    # Mask the MSE loss where the first node's true label is 0\n",
    "    mask = tf.cast(y_true[..., 0] > 0, tf.float32)  # Shape (batch_size, N)\n",
    "    masked_mse_loss = mse_loss * mask  # Shape (batch_size, N)\n",
    "    \n",
    "    # Manually calculate binary cross-entropy for the first node\n",
    "    epsilon = 1e-7  # Small constant to prevent log(0)\n",
    "    y_pred_clipped = tf.clip_by_value(y_pred[..., 0], epsilon, 1.0 - epsilon)\n",
    "    bce_loss = -(y_true[..., 0] * tf.math.log(y_pred_clipped) + (1 - y_true[..., 0]) * tf.math.log(1 - y_pred_clipped))  # Shape (batch_size, N)\n",
    "\n",
    "    # Weighting each bin by weight_func(SNR), where SNR is the 3rd node label\n",
    "    snr = y_true[..., 2]  # SNR is the 3rd node label, shape (batch_size, N)\n",
    "    weights = tf.where(snr < 0, tf.ones_like(snr), weight_func(snr))  # If SNR < 0, weight is 1 (fully weight the BCE loss for non-peak bins), else apply weight_func\n",
    "\n",
    "    # Apply weights to the masked MSE loss\n",
    "    weighted_mse_loss = masked_mse_loss * weights  # Shape (batch_size, N)\n",
    "    \n",
    "    # Apply weights to the BCE loss\n",
    "    weighted_bce_loss = bce_loss * weights  # Shape (batch_size, N)\n",
    "\n",
    "    # Average weighted MSE, BCE losses across bins (N) for each sample\n",
    "    mean_mse_loss_per_sample = tf.reduce_mean(weighted_mse_loss, axis=1)  # Mean over N for shape (batch_size,)\n",
    "    mean_bce_loss_per_sample = tf.reduce_mean(weighted_bce_loss, axis=1)\n",
    "\n",
    "    # Combine and average across the batch\n",
    "    total_loss = tf.reduce_mean(mean_bce_loss_per_sample + mean_mse_loss_per_sample)  # Mean over batch size\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def peak_counting_error(isolated_labels, predictions):\n",
    "    \"\"\"\n",
    "    Computes the best threshold to minimize peak counting error.\n",
    "\n",
    "    Args:\n",
    "    - isolated_labels: Tensor of shape (M, N), where `1` indicates a true peak.\n",
    "    - predictions: Tensor of shape (M, N), with predicted scores for each bin.\n",
    "\n",
    "    Returns:\n",
    "    - best_error: The minimum peak counting error across all thresholds.\n",
    "    \"\"\"\n",
    "    M = tf.shape(isolated_labels)[0]  # Number of samples\n",
    "    tf.debugging.assert_equal(\n",
    "        M, tf.shape(predictions)[0],\n",
    "        message=\"Mismatch in number of samples between isolated_labels and predictions!\"\n",
    "    )\n",
    "\n",
    "    best_error = tf.Variable(float('inf'), dtype=tf.float32)\n",
    "    best_thresh = tf.Variable(0.0, dtype=tf.float32)\n",
    "\n",
    "    # Iterate through multiple thresholds\n",
    "    for thresh in [0.5, 0.6, 0.7, 0.8, 0.9, 0.95]:\n",
    "        current_error = tf.Variable(0.0, dtype=tf.float32)  # Initialize current_error as a tf.Variable\n",
    "        predictions_snapped = tf.cast(predictions > thresh, tf.int32)\n",
    "\n",
    "        # Process each row (sample)\n",
    "        for row in tf.range(M):  # Use tf.range for TensorFlow-compatible iteration\n",
    "            predictions_row = predictions_snapped[row, :]\n",
    "            isolated_labels_row = isolated_labels[row, :]\n",
    "\n",
    "            # Initialize chunk tracking\n",
    "            current_chunk_value = predictions_row[0]\n",
    "            current_chunk_start = 0\n",
    "\n",
    "            # Process each index\n",
    "            for idx in tf.range(1, tf.shape(predictions_row)[0] + 1):  # +1 to handle the last chunk\n",
    "                is_last_chunk = idx == tf.shape(predictions_row)[0]\n",
    "                is_new_chunk = not is_last_chunk and predictions_row[idx] != current_chunk_value\n",
    "\n",
    "                if is_last_chunk or is_new_chunk:\n",
    "                    # Process the current chunk\n",
    "                    chunk_end = idx\n",
    "                    chunk_labels = isolated_labels_row[current_chunk_start:chunk_end]\n",
    "\n",
    "                    # Count predicted peaks and actual peaks in the chunk\n",
    "                    predicted_peaks = tf.cast(current_chunk_value, tf.float32)\n",
    "                    print(chunk_labels)\n",
    "                    actual_peaks = tf.reduce_sum(chunk_labels)\n",
    "                    # Ensure actual_peaks is scalar\n",
    "                    actual_peaks = tf.squeeze(actual_peaks)\n",
    "\n",
    "                    # Add squared error to total error\n",
    "                    current_error.assign_add((predicted_peaks - actual_peaks) ** 2)\n",
    "\n",
    "                    # Start a new chunk\n",
    "                    if not is_last_chunk:\n",
    "                        current_chunk_value = predictions_row[idx]\n",
    "                    current_chunk_start = idx\n",
    "\n",
    "        # Average the error across all samples\n",
    "        current_error.assign(current_error / tf.cast(M, tf.float32))\n",
    "\n",
    "        # Update the best error and threshold\n",
    "        if current_error < best_error:\n",
    "            best_error.assign(current_error)\n",
    "            best_thresh.assign(thresh)\n",
    "\n",
    "    tf.print(f\"Best threshold: {best_thresh}, Best Peak Counting Error: {best_error}\")\n",
    "    return best_error\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "class ValidationMetricCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data, metric_name=\"peak_counting_error\"):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "        self.metric_name = metric_name\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_x, (val_y, val_isolated_labels) = self.validation_data  # Unpack extra labels\n",
    "        val_predictions = self.model.predict(val_x, verbose=0)\n",
    "        \n",
    "        # Compute your custom metric (e.g., Mean Absolute Error)\n",
    "        val_metric = peak_counting_error(val_isolated_labels, val_predictions)\n",
    "\n",
    "        # Add the validation metric to logs\n",
    "        logs[self.metric_name] = val_metric.numpy()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}: {self.metric_name} = {val_metric.numpy()}\")\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define name for this model\n",
    "model_version = \"PP_V1\"\n",
    "\n",
    "# Define the input length / number of frequency bins (N)\n",
    "N = 8192\n",
    "\n",
    "# Input layer\n",
    "input_layer = Input(shape=(N, 1), name=\"Input\")\n",
    "\n",
    "# Inception-like layer with 1D convolutions\n",
    "convs = []\n",
    "# We'll base our kernel choices on the hwhm distribution of the peaks. \n",
    "# Thin peaks are in 3Hz-10Hz range --> 5-15 bins\n",
    "# Wide peaks are in 10Hz-100Hz range --> 15-149 bins\n",
    "# We choose filters at a range of scales, odd (to facilitate being cenetered around a peak)\n",
    "# and we want more filters for the medium-small range since there are more peaks at this scale.\n",
    "# Otherwise largely arbitrarily.\n",
    "kernels = [(3, 4), (5, 8), (9, 16), (15, 32), (31, 32), (55, 32), (71, 16), (101, 8), (149, 4), (201, 2)]\n",
    "for kernel_size, num_filters in kernels:\n",
    "    convs.append(Conv1D(num_filters, kernel_size=kernel_size, activation='relu', padding='same', name=f\"Conv_{kernel_size}\")(input_layer))\n",
    "\n",
    "# Concatenate the outputs of all convolutional layers\n",
    "concat_layer = Concatenate(name=\"Inception_Concat\")(convs)\n",
    "\n",
    "# Time Distributed Dense Layers\n",
    "td_dense64 = TimeDistributed(Dense(64, activation='relu'), name=\"Dense_64\")(concat_layer)\n",
    "td_dense32A = TimeDistributed(Dense(32, activation='relu'), name=\"Dense_32A\")(td_dense64)\n",
    "# bd_LSTM = Bidirectional(LSTM(16, return_sequences=True), name=\"LSTM\")(td_dense32A)\n",
    "# td_dense32B = TimeDistributed(Dense(32, activation='relu'), name=\"Dense_32B\")(bd_LSTM)\n",
    "td_dense32B = TimeDistributed(Dense(32, activation='relu'), name=\"Dense_32B\")(td_dense32A)\n",
    "td_dense16 = TimeDistributed(Dense(16, activation='relu'), name=\"Dense_16\")(td_dense32B)\n",
    "\n",
    "# Final layer with 3 outputs per input bin\n",
    "output = TimeDistributed(Dense(3, activation=None), name=\"Output\")(td_dense16)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=input_layer, outputs=output, name=model_version)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=custom_loss, metrics=[peak_counting_error])\n",
    "\n",
    "# Summary\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_317/3159667805.py\", line 94, in peak_counting_error  *\n        if is_last_chunk or is_new_chunk:\n\n    ValueError: condition of if statement expected to be `tf.bool` scalar, got [False False False]; to check for None, use `is not None`\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 20\u001b[0m\n\u001b[1;32m     11\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     ValidationMetricCallback(validation_data\u001b[38;5;241m=\u001b[39m(X_val, (y_val, isolated_peaks_val)), metric_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeak_counting_error\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     13\u001b[0m     EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeak_counting_error\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39mpatience, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),  \u001b[38;5;66;03m# Stop if no improvement for 5 epochs\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     ModelCheckpoint(weight_path, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Save the best model\u001b[39;00m\n\u001b[1;32m     15\u001b[0m ]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# Training data\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# Training labels\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Validation data\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Number of epochs\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Batch size\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Add callbacks for early stopping and checkpointing\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# Verbose output\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_history.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     31\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(history\u001b[38;5;241m.\u001b[39mhistory, file)\n",
      "File \u001b[0;32m/fs/ess/PAS2038/PHYSICS_5680_OSU/jupyter/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file9qe273f1.py:132\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__peak_counting_error\u001b[0;34m(isolated_labels, predictions)\u001b[0m\n\u001b[1;32m    130\u001b[0m predicted_peaks \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_peaks\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    131\u001b[0m current_error \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 132\u001b[0m ag__\u001b[38;5;241m.\u001b[39mfor_stmt([\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.6\u001b[39m, \u001b[38;5;241m0.7\u001b[39m, \u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m0.95\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m, loop_body_2, get_state_5, set_state_5, (), {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterate_names\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthresh\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m    133\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mprint, (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mag__\u001b[38;5;241m.\u001b[39mld(best_thresh)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Best Peak Counting Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mag__\u001b[38;5;241m.\u001b[39mld(best_error)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file9qe273f1.py:101\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__peak_counting_error.<locals>.loop_body_2\u001b[0;34m(itr_2)\u001b[0m\n\u001b[1;32m     99\u001b[0m         ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mor_(\u001b[38;5;28;01mlambda\u001b[39;00m : ag__\u001b[38;5;241m.\u001b[39mld(is_last_chunk), \u001b[38;5;28;01mlambda\u001b[39;00m : ag__\u001b[38;5;241m.\u001b[39mld(is_new_chunk)), if_body_1, else_body_1, get_state_1, set_state_1, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_chunk_start\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_chunk_value\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    100\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mfor_stmt(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mrange, (\u001b[38;5;241m1\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mshape, (ag__\u001b[38;5;241m.\u001b[39mld(predictions_row),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), \u001b[38;5;28;01mNone\u001b[39;00m, loop_body, get_state_2, set_state_2, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_chunk_start\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_chunk_value\u001b[39m\u001b[38;5;124m'\u001b[39m), {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterate_names\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124midx\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m--> 101\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrange\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_body_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterate_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(current_error)\u001b[38;5;241m.\u001b[39massign, (ag__\u001b[38;5;241m.\u001b[39mld(current_error) \u001b[38;5;241m/\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mld(M), ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mfloat32), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_4\u001b[39m():\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file9qe273f1.py:100\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__peak_counting_error.<locals>.loop_body_2.<locals>.loop_body_1\u001b[0;34m(itr_1)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mor_(\u001b[38;5;28;01mlambda\u001b[39;00m : ag__\u001b[38;5;241m.\u001b[39mld(is_last_chunk), \u001b[38;5;28;01mlambda\u001b[39;00m : ag__\u001b[38;5;241m.\u001b[39mld(is_new_chunk)), if_body_1, else_body_1, get_state_1, set_state_1, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_chunk_start\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_chunk_value\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 100\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrange\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions_row\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcurrent_chunk_start\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcurrent_chunk_value\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterate_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43midx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file9qe273f1.py:99\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__peak_counting_error.<locals>.loop_body_2.<locals>.loop_body_1.<locals>.loop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m current_chunk_start, current_chunk_value\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mor_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_last_chunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_new_chunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcurrent_chunk_start\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcurrent_chunk_value\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_317/3159667805.py\", line 94, in peak_counting_error  *\n        if is_last_chunk or is_new_chunk:\n\n    ValueError: condition of if statement expected to be `tf.bool` scalar, got [False False False]; to check for None, use `is not None`\n"
     ]
    }
   ],
   "source": [
    "# Define batch size, number of epochs, and patience\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    "patience = 3\n",
    "\n",
    "weight_path = os.path.join(\"PP Weights\", f\"{model_version}.keras\")\n",
    "\n",
    "\n",
    "\n",
    "# Add callbacks for better training\n",
    "callbacks = [\n",
    "    ValidationMetricCallback(validation_data=(X_val, (y_val, isolated_peaks_val)), metric_name=\"peak_counting_error\"),\n",
    "    EarlyStopping(monitor=\"peak_counting_error\", patience=patience, restore_best_weights=True, verbose=1),  # Stop if no improvement for 5 epochs\n",
    "    ModelCheckpoint(weight_path, save_best_only=True, monitor='val_loss')  # Save the best model\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,                # Training data\n",
    "    y_train,                # Training labels\n",
    "    validation_data=(X_val, y_val),  # Validation data\n",
    "    epochs=epochs,        # Number of epochs\n",
    "    batch_size=batch_size,  # Batch size\n",
    "    callbacks=callbacks,    # Add callbacks for early stopping and checkpointing\n",
    "    verbose=1               # Verbose output\n",
    ")\n",
    "\n",
    "with open(f'{model_version}_history.pkl', 'wb') as file:\n",
    "    pickle.dump(history.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss = model.evaluate(X_test, y_test, verbose=1)  # Verbose output for evaluation\n",
    "\n",
    "print(\"Test Loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Custom Loss\n",
    "# Example data: batch_size=4, N=5, nodes=3\n",
    "y_true = np.array([\n",
    "    [[0, 0.5, 0.7], [0, 0.2, -1], [0, 10000, -1000], [0, 0.3, 10], [0, 0.1, 10]],  # Sample 1\n",
    "    [[0, 0.6, 0.3], [1, 0.1, -1], [1, 0.3, 10], [0, 0.4, 10], [0, 0.7, 10]],  # Sample 2\n",
    "    [[0, 0.4, 1.5], [1, 0.8, -1], [1, 0.6, 10], [1, 0.2, 10], [0, 0.9, 10]],  # Sample 3\n",
    "    [[0, 0.5, 0.6], [0, 0.3, -1], [0, 0.7, 10], [1, 0.1, 10], [0, 0.8, 10]],  # Sample 4\n",
    "])\n",
    "\n",
    "y_pred = np.array([\n",
    "    [[0.9, 0.6, 0.8], [0.9, 0.3, 0.5], [0.5, 100000, 1000], [0.7, 0.4, 0.6], [0.2, 0.1, 0.3]],  # Sample 1\n",
    "    [[0.7, 0.5, 0.4], [0.9, 0.2, 0.3], [0.9, 0.4, 0.6], [0.6, 0.7, 0.9], [0.8, 0.7, 0.8]],  # Sample 2\n",
    "    [[0.8, 0.4, 0.5], [0.9, 0.6, 0.8], [0.9, 0.7, 0.5], [0.9, 0.3, 0.6], [0.2, 0.9, 0.7]],  # Sample 3\n",
    "    [[0.9, 0.4, 0.3], [0.9, 0.6, 0.8], [0.6, 0.9, 0.7], [0.9, 0.3, 0.5], [0.8, 0.7, 0.6]],  # Sample 4\n",
    "])\n",
    "\n",
    "# Convert to tensors\n",
    "y_true_tensor = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
    "y_pred_tensor = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
    "\n",
    "loss_value = custom_loss(y_true_tensor, y_pred_tensor)\n",
    "print(\"Loss Value:\", loss_value.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a sample\n",
    "i = 1\n",
    "spectrum = X_train[i]\n",
    "f = rfftfreq(32768, 1/44100)[0:8192]\n",
    "\n",
    "labels = y_train[i, :, :]\n",
    "spread_peak_labels = labels[:, 0]\n",
    "indices = np.where(spread_peak_labels == 1)[0]\n",
    "# isolated_peaks = isolated_peaks_train[i]\n",
    "# indices = np.where(isolated_peaks == 1)[0]\n",
    "plt.scatter(f, spectrum, color='blue', s=1)\n",
    "plt.scatter(f[indices], spectrum[indices], color='red', s=1)\n",
    "plt.xlim(3000, 4000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify peak_counting_error\n",
    "val_isolated_labels=np.array(\n",
    "    [[0, 1, 0, 0, 1], \n",
    "     [1, 0, 1, 0, 0]]\n",
    "    )\n",
    "val_predictions=np.array(\n",
    "    [[0.81, 0.91, 0.71, 0.31, 0.91],\n",
    "     [0.81, 0.21, 0.91, 0.96, 0.91]]\n",
    "    )\n",
    "\n",
    "peak_counting_error(val_isolated_labels, val_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out how many bins our peaks are\n",
    "f = rfftfreq(32768, 1/44100)\n",
    "# HWFM (in bins) of a peak with a HWHM of 100Hz\n",
    "bin_width = f[1] - f[0]\n",
    "print(f\"HWFM (in bins) of a peak with a HWHM of 100Hz: {200 / bin_width}\")\n",
    "print(f\"HWFM (in bins) of a peak with a HWHM of 10Hz: {20 / bin_width}\")\n",
    "print(f\"HWFM (in bins) of a peak with a HWHM of 3Hz: {6 / bin_width}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
