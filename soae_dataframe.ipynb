{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from plots import *\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def plot_mags(path, t_win=1, sf=False):\n",
    "    wf = np.loadtxt(path)\n",
    "    m = get_mags(wf, sr=44100, t_win=t_win, dict=True)\n",
    "    mags = m['mags']\n",
    "    freq_ax = m['freq_ax']\n",
    "    plt.plot(freq_ax, np.log10(mags)*10)\n",
    "    plt.title(str(path).split(\"\\\\\")[-1])\n",
    "    if sf:\n",
    "        plt.savefig(str(path).split(\"\\\\\")[-1].split(\".\")[0] + \".png\")\n",
    "    plt.show()\n",
    "def plot_supp(path, save=False):\n",
    "    data = np.loadtxt(path)\n",
    "    freqs = data[:, 0]\n",
    "    mags = data[:, 1]\n",
    "    plt.plot(freqs, mags)\n",
    "    plt.title(str(path).split(\"\\\\\")[-1])\n",
    "    if save:\n",
    "        plt.savefig(str(path).split(\"\\\\\")[-1].split(\".\")[0] + \".png\")\n",
    "    plt.show()\n",
    "\n",
    "def has_supptone(data, cutoff=300):\n",
    "    # find cutoff freq, check if anything above this has > 20 dB\n",
    "    freqs = data[:, 0]\n",
    "    mags = data[:, 1]\n",
    "    # print(np.where(freqs > cutoff))\n",
    "    i_cutoff = np.where(freqs > cutoff)[0][0]\n",
    "    if np.max(mags[i_cutoff:]) > 20:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "# get the main directory in my computer\n",
    "main_path_str = \"C:\\\\Users\\\\Owner\\OneDrive\\\\Desktop\\\\SOAE Data\\\\\"\n",
    "main_path = Path(main_path_str)\n",
    "# we'll process each subfolder separately since each is likely to have its own quirks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plotting particular files\n",
    "\"\"\"\n",
    "# path1 = \"C:\\\\Users\\\\Owner\\OneDrive\\\\Desktop\\\\SOAE Data\\\\Pre-2014 Data\\\\Geckos et al MIT\\\\\"\n",
    "# path2 = \"01.26.05\\\\\"\n",
    "# path1 = r\"C:\\Users\\Owner\\OneDrive\\Desktop\\SOAE Data\\Pre-2014 Data\\Human (UofA S&A via Wiggio)\"\n",
    "# path2 = \"\\\\07.02.09\"\n",
    "path1 = r\"C:\\Users\\Owner\\OneDrive\\Desktop\\SOAE Data\\Pre-2014 Data\\Lizards CUMC2011\"\n",
    "path2 = r\"\\05.16.11\"\n",
    "# path1 = r\"C:\\Users\\Owner\\OneDrive\\Desktop\\SOAE Data\\York Data\"\n",
    "# path2 = r\"\\04.12.17\"\n",
    "save = False\n",
    "for fp in Path(path1+path2).rglob('*'):\n",
    "    fn = fp.name\n",
    "    ext = fp.suffix\n",
    "    if \"README\" in fn or ext in ('.rtf' '.pdf'):\n",
    "        print(f\"Skipping {fn}\")\n",
    "        continue\n",
    "    try:\n",
    "        plot_supp(fp, save=save)\n",
    "    except:\n",
    "        print(\"Waveform detecting, calculating mags\")\n",
    "        plot_mags(fp, t_win=1, sf=save)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Testing has_supptone()\n",
    "\"\"\"\n",
    "folder = \"Pre-2014 Data\"\n",
    "    \n",
    "# We'll build our dataframe by making a dictionary of lists and appending to them\n",
    "dataframe = {\n",
    "    'filepath': [],\n",
    "    'data': [],  \n",
    "    'species': [],\n",
    "    'sr': [],\n",
    "}\n",
    "\n",
    "# First navigate to our directory\n",
    "directory_path = Path(main_path_str + folder)\n",
    "\n",
    "# track which file we're on\n",
    "n_files = sum(1 for _ in directory_path.rglob('*') if _.is_file())\n",
    "n_current=0\n",
    "# now loop through all files in that collection\n",
    "for fp in directory_path.rglob('*'):\n",
    "    # Make sure it's a file\n",
    "    if fp.is_file() == False:  \n",
    "        continue\n",
    "    \n",
    "    # track which file we're on\n",
    "    n_current += 1\n",
    "    print(f\"Processing file {n_current}/{n_files}\")\n",
    "    \n",
    "    # Get various versions of the filepath/filename\n",
    "    \n",
    "    # Cut off the beginning of the filepath since it's unnecessary for our dataframe (fps = file path shortened)\n",
    "    fps = str(fp.relative_to(main_path))\n",
    "    \n",
    "    # Also get subfolder (if applicable)\n",
    "    if len(fps.split(\"\\\\\")) > 1:\n",
    "        subfolder = fps.split(\"\\\\\")[1]\n",
    "    else:\n",
    "        subfolder = \"NA\"\n",
    "        \n",
    "    # Get the filename itself (without its containing folders), extension, and uppercase version\n",
    "    fn = fp.name\n",
    "    ext = fp.suffix\n",
    "    fnU = fn.upper()\n",
    "    \n",
    "    # Treat different files differently based on keywords in filename\n",
    "    if \"README\" in fnU or ext not in ('.txt' '.mat'):\n",
    "        continue\n",
    "    \n",
    "    elif \"TUBE\" in fnU:\n",
    "        continue\n",
    "    \n",
    "    elif \"SUPP\" in fnU:\n",
    "        if ext == '.txt':\n",
    "            data = np.loadtxt(fp)\n",
    "        else:\n",
    "            raise ValueError(f\"Supp file from {fps} isn't .txt!\")\n",
    "        try: \n",
    "            if data.shape[1] != 2:\n",
    "                raise RuntimeError(f\"Supp file from {fps} isn't two columns!\")\n",
    "        except:\n",
    "            raise(f\"Supp file from {fps} isn't 2D!\")\n",
    "        if has_supptone(data):\n",
    "            plot_supp(fp)\n",
    "            print(\"This one has a suppression tone!\")\n",
    "        else:\n",
    "            plot_supp(fp)\n",
    "            print(\"This one doesn't have a suppression tone!\")\n",
    "    if n_current > 10:\n",
    "        break\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all DFs into one\n",
    "dfs = []\n",
    "for df_title in [\"Curated Data\", \"Extra Owl\", \"Lots of Data\", \"Pre-2014 Data\"]:\n",
    "    dfs.append(pd.read_parquet(df_title + \".parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"UWO Data\"\n",
    "    \n",
    "# We'll build our dataframe by making a dictionary of lists and appending to them\n",
    "dataframe = {\n",
    "    'filepath': [],\n",
    "    'freqs': [],\n",
    "    'spectrum': [],\n",
    "    'wf': [],\n",
    "    'species': [],\n",
    "    'sr': [],\n",
    "}\n",
    "\n",
    "# First navigate to our directory\n",
    "directory_path = Path(main_path_str + folder)\n",
    "\n",
    "# track which file we're on\n",
    "n_files = sum(1 for _ in directory_path.rglob('*') if _.is_file())\n",
    "\n",
    "# track how many of each filetype we have\n",
    "n_current = 0\n",
    "n_readme = 0\n",
    "n_tube = 0\n",
    "n_oral = 0\n",
    "n_earsoae = 0\n",
    "n_supptone = 0\n",
    "n_suppgood = 0\n",
    "n_wf = 0\n",
    "\n",
    "unknownspecies = []\n",
    "earsoae = []\n",
    "\n",
    "# now loop through all files in that collection\n",
    "for fp in directory_path.rglob('*'):\n",
    "    # Make sure it's a file\n",
    "    if fp.is_file() == False:  \n",
    "        continue\n",
    "    \n",
    "    # Get various versions of the filepath/filename\n",
    "    \n",
    "    # Cut off the beginning of the filepath since it's unnecessary for our dataframe (fps = file path shortened)\n",
    "    main_path = Path(main_path_str)\n",
    "    fps = str(fp.relative_to(main_path))\n",
    "    \n",
    "    # Also get subfolder (if applicable)\n",
    "    if len(fps.split(\"\\\\\")) > 1:\n",
    "        subfolder = fps.split(\"\\\\\")[1]\n",
    "    else:\n",
    "        subfolder = \"NA\"\n",
    "        \n",
    "    # Get the filename itself (without its containing folders), extension, and uppercase version\n",
    "    fn = fp.name\n",
    "    ext = fp.suffix\n",
    "    fnU = fn.upper()\n",
    "\n",
    "    # Treat different files differently based on keywords in filename\n",
    "    \n",
    "    if \"README\" in fnU or ext not in ('.txt' '.mat'):\n",
    "        # print(f\"Skipping {fps} -- README or wrong extension\")\n",
    "        n_readme += 1\n",
    "        continue\n",
    "    \n",
    "    elif \"TUBE\" in fnU:\n",
    "        # print(f\"Skipping {fps} -- Tube file\")\n",
    "        n_tube += 1\n",
    "        continue\n",
    "    \n",
    "    elif \"SUPP\" in fnU and \"SOAE\" in fnU:\n",
    "        if ext == '.txt':\n",
    "            data = np.loadtxt(fp)\n",
    "        else:\n",
    "            raise ValueError(f\"Supp file from {fps} isn't .txt!\")\n",
    "        try: \n",
    "            if data.shape[1] != 2:\n",
    "                raise RuntimeError(f\"Supp file from {fps} isn't two columns!\")\n",
    "        except:\n",
    "            raise(f\"Supp file from {fps} isn't 2D!\")\n",
    "        if has_supptone(data):\n",
    "            # plot_supp(fp)\n",
    "            print(f\"Skipping {fps} -- true suppression tone!\")\n",
    "            n_supptone += 1\n",
    "            if \"NOSUPP\" in fnU:\n",
    "                raise RuntimeError(f\"Our suppression tone detector is wrong! {fps} shouldn't have a suppression tone...\")\n",
    "            continue\n",
    "        else:\n",
    "            # pull out frequency axis and spectrum and add to dataframe dictionary\n",
    "            freqs = data[:, 0]\n",
    "            spectrum = data[:, 1]\n",
    "            dataframe['freqs'].append(freqs)\n",
    "            dataframe['spectrum'].append(spectrum)\n",
    "            # add a samplerate of 0 and an empty value to the waveform to fill the space\n",
    "            dataframe['sr'].append(0)\n",
    "            dataframe['wf'].append(None)\n",
    "            # record we got a good one\n",
    "            n_suppgood += 1\n",
    "    \n",
    "    elif (\"EAR\" in fnU and \"SOAE\" in fnU) and (\"WF\" not in fnU and \"WAVEFORM\" not in fnU and \"SUPP\" not in fnU):\n",
    "        print(f\"Skipping {fps} -- Chris can't say if good or not\")\n",
    "        earsoae.append[fps]\n",
    "        n_earsoae += 1\n",
    "        continue\n",
    "    \n",
    "    elif \"WF\" in fnU or \"WAVEFORM\" in fnU:\n",
    "    # we must have a waveform if we got here\n",
    "        # Check if it's a .txt or .mat file\n",
    "        try:\n",
    "            if ext == '.mat':\n",
    "                mat = scipy.io.loadmat(fp)\n",
    "                if 'wf' in mat:\n",
    "                    wf = np.squeeze(mat['wf'])\n",
    "                else: \n",
    "                    print(f\"Not sure how to process {fps}\")\n",
    "            if ext == '.txt':\n",
    "                wf = np.loadtxt(fp)\n",
    "            # Let's make sure this waveform is a 1D array\n",
    "            if len(wf.shape) > 1:\n",
    "                raise RuntimeError(f\"Waveform from {fps} isn't 1D!\")\n",
    "            # add to the dataframe \n",
    "            dataframe['sr'].append(44100)\n",
    "            dataframe['wf'].append(wf)\n",
    "            # add empty values to the spectrum and freqs to fill the space\n",
    "            dataframe['freqs'].append(None)\n",
    "            dataframe['spectrum'].append(None)\n",
    "            n_wf += 1\n",
    "        except:\n",
    "            f\"Uh oh! Issue when loading {fps}\"\n",
    "    else:\n",
    "        raise RuntimeError(f\"UH OH {fps} didn't fall into any categories:\")\n",
    "        \n",
    "            \n",
    "            \n",
    "    # Get species\n",
    "    if fn[0:2] == \"TH\":\n",
    "        species = \"Human\"\n",
    "    elif fn[0:2] == \"AP\":\n",
    "        species = \"AP\"\n",
    "    else:\n",
    "        species = \"Unknown\"\n",
    "        unknownspecies.append(fps)\n",
    "        # raise ValueError(f\"Couldn't find species for {fps}!\")\n",
    "\n",
    "    dataframe['filepath'].append(fps)\n",
    "    dataframe['species'].append(species)\n",
    "    \n",
    "    # track which file we're on\n",
    "    n_current += 1\n",
    "    print(f\"Processed file {n_current}/{n_files}: {fps}\")\n",
    "\n",
    "print(f\"FP: {len(dataframe['filepath'])}, SR: {len(dataframe['sr'])}, Spectrum: {len(dataframe['spectrum'])}, wf: {len(dataframe['wf'])}, freqs: {len(dataframe['freqs'])}, Species: {len(dataframe['species'])}\"), \n",
    "print(f\"Finished! Ignored {n_oral} mouth/oral files, {n_readme} README files, {n_tube} tube files, {n_earsoae} earsoae files, {n_supptone} suppression tone files\")\n",
    "print(f\"We kept {n_suppgood} good suppression files and {n_wf} waveform files.\")\n",
    "print(f\"Here's some to ask Chris if they're okay:\")\n",
    "for f in earsoae:\n",
    "    print(f)\n",
    "print()\n",
    "print()\n",
    "print(f\"Here's some to ask Chris about species:\")\n",
    "for f in unknownspecies:\n",
    "    print(f)\n",
    "\n",
    "# turn this into a pandas dataframe\n",
    "df = pd.DataFrame(dataframe)\n",
    "# save this as a parquet file for efficient dataframe storage (use pyarrow since the 'wf' column has different length lists)\n",
    "df.to_parquet(f'{folder}.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"York Data\"\n",
    "    \n",
    "# We'll build our dataframe by making a dictionary of lists and appending to them\n",
    "dataframe = {\n",
    "    'filepath': [],\n",
    "    'freqs': [],\n",
    "    'spectrum': [],\n",
    "    'wf': [],\n",
    "    'species': [],\n",
    "    'sr': [],\n",
    "}\n",
    "\n",
    "# First navigate to our directory\n",
    "directory_path = Path(main_path_str + folder)\n",
    "\n",
    "# track which file we're on\n",
    "n_files = sum(1 for _ in directory_path.rglob('*') if _.is_file())\n",
    "\n",
    "# track how many of each filetype we have\n",
    "n_current = 0\n",
    "n_readme = 0\n",
    "n_tube = 0\n",
    "n_oral = 0\n",
    "n_earsoae = 0\n",
    "n_supptone = 0\n",
    "n_suppgood = 0\n",
    "n_dual = 0\n",
    "n_wf = 0\n",
    "\n",
    "unknownspecies = []\n",
    "\n",
    "# now loop through all files in that collection\n",
    "for fp in directory_path.rglob('*'):\n",
    "    # Make sure it's a file\n",
    "    if fp.is_file() == False:  \n",
    "        continue\n",
    "    \n",
    "    if n_current > 500:\n",
    "        break\n",
    "\n",
    "    # Get various versions of the filepath/filename\n",
    "    \n",
    "    # Cut off the beginning of the filepath since it's unnecessary for our dataframe (fps = file path shortened)\n",
    "    main_path = Path(main_path_str)\n",
    "    fps = str(fp.relative_to(main_path))\n",
    "    \n",
    "    # Also get subfolder (if applicable)\n",
    "    if len(fps.split(\"\\\\\")) > 1:\n",
    "        subfolder = fps.split(\"\\\\\")[1]\n",
    "    else:\n",
    "        subfolder = \"NA\"\n",
    "        \n",
    "    # Get the filename itself (without its containing folders), extension, and uppercase version\n",
    "    fn = fp.name\n",
    "    ext = fp.suffix\n",
    "    fnU = fn.upper()\n",
    "\n",
    "    # Treat different files differently based on keywords in filename\n",
    "    \n",
    "    if \"README\" in fnU or ext not in ('.txt' '.mat'):\n",
    "        # print(f\"Skipping {fps} -- README or wrong extension\")\n",
    "        n_readme += 1\n",
    "        continue\n",
    "    \n",
    "    elif \"TUBE\" in fnU:\n",
    "        # print(f\"Skipping {fps} -- Tube file\")\n",
    "        n_tube += 1\n",
    "        continue\n",
    "    \n",
    "    elif \"ORAL\" in fnU or \"MOUTH\" in fnU:\n",
    "        # print(f\"Skipping {fps} -- Oral file\")\n",
    "        n_oral += 1\n",
    "        continue\n",
    "    \n",
    "    elif \"DUAL\" in fnU and \"LEFT\" not in fnU and \"RIGHT\" not in fnU:\n",
    "        # These files have two columns, one for each ear. We'll process them as separate waveforms.\n",
    "        if ext == '.txt':\n",
    "            wfs = np.loadtxt(fp)\n",
    "        else:\n",
    "            raise ValueError(f\"Waveform from {fps} isn't .txt!\")\n",
    "        for i in (0, 1):\n",
    "            # add both to the dataframe \n",
    "            dataframe['sr'].append(44100)\n",
    "            dataframe['wf'].append(wfs[:, i])\n",
    "            # add empty values to the spectrum and freqs to fill the space\n",
    "            dataframe['freqs'].append(None)\n",
    "            dataframe['spectrum'].append(None)\n",
    "            # now we also must add the species and filepath\n",
    "            dataframe['species'].append(\"Anolis\")\n",
    "            dataframe['filepath'].append(fps + f\" Column {i + 1}\")\n",
    "            n_wf += 1\n",
    "        # then wrap things up and continue so this doesn't happen twice\n",
    "        n_current += 1\n",
    "        print(f\"Processed file {n_current}/{n_files}: {fps}\")\n",
    "        continue\n",
    "    \n",
    "    elif \"SUPP\" in fnU and \"SOAE\" in fnU:\n",
    "        if ext == '.txt':\n",
    "            data = np.loadtxt(fp)\n",
    "        else:\n",
    "            raise ValueError(f\"Supp file from {fps} isn't .txt!\")\n",
    "        try: \n",
    "            if data.shape[1] != 2:\n",
    "                raise RuntimeError(f\"Supp file from {fps} isn't two columns!\")\n",
    "        except:\n",
    "            raise(f\"Supp file from {fps} isn't 2D!\")\n",
    "        if has_supptone(data):\n",
    "            # plot_supp(fp)\n",
    "            print(f\"Skipping {fps} -- true suppression tone!\")\n",
    "            n_supptone += 1\n",
    "            if \"NOSUPP\" in fnU:\n",
    "                raise RuntimeError(f\"Our suppression tone detector is wrong! {fps} shouldn't have a suppression tone...\")\n",
    "            continue\n",
    "        else:\n",
    "            # pull out frequency axis and spectrum and add to dataframe dictionary\n",
    "            freqs = data[:, 0]\n",
    "            spectrum = data[:, 1]\n",
    "            dataframe['freqs'].append(freqs)\n",
    "            dataframe['spectrum'].append(spectrum)\n",
    "            # add a samplerate of 0 and an empty value to the waveform to fill the space\n",
    "            dataframe['sr'].append(0)\n",
    "            dataframe['wf'].append(None)\n",
    "            # record we got a good one\n",
    "            n_suppgood += 1\n",
    "    \n",
    "    elif (\"EAR\" in fnU and \"SOAE\" in fnU) and (\"WF\" not in fnU and \"WAVEFORM\" not in fnU and \"SUPP\" not in fnU):\n",
    "        print(f\"Skipping {fps} -- Chris can't say if good or not\")\n",
    "        n_earsoae += 1\n",
    "        continue\n",
    "    \n",
    "    elif \"WF\" in fnU or \"WAVEFORM\" in fnU:\n",
    "    # we must have a waveform if we got here\n",
    "        # Check if it's a .txt or .mat file\n",
    "        try:\n",
    "            if ext == '.mat':\n",
    "                mat = scipy.io.loadmat(fp)\n",
    "                if 'wf' in mat:\n",
    "                    wf = np.squeeze(mat['wf'])\n",
    "                else: \n",
    "                    print(f\"Not sure how to process {fps}\")\n",
    "            if ext == '.txt':\n",
    "                wf = np.loadtxt(fp)\n",
    "            # Let's make sure this waveform is a 1D array\n",
    "            if len(wf.shape) > 1:\n",
    "                raise RuntimeError(f\"Waveform from {fps} isn't 1D!\")\n",
    "            # add to the dataframe \n",
    "            dataframe['sr'].append(44100)\n",
    "            dataframe['wf'].append(wf)\n",
    "            # add empty values to the spectrum and freqs to fill the space\n",
    "            dataframe['freqs'].append(None)\n",
    "            dataframe['spectrum'].append(None)\n",
    "            n_wf += 1\n",
    "        except:\n",
    "            raise RuntimeError(f\"Uh oh! Issue when loading {fps}\")\n",
    "    else:\n",
    "        raise RuntimeError(f\"UH OH {fps} didn't fall into any categories:\")\n",
    "        \n",
    "            \n",
    "            \n",
    "    # Get species\n",
    "    if fn[0:2] == \"AC\" or \"ACsb\" in fn:\n",
    "        species = \"Anolis\"\n",
    "    elif fn[0:2] in (\"AL\", \"NT\", \"EA\", \"CB\", \"JL\", \"LS\", \"KH\", \"LM\", \"JI\"):\n",
    "        species = \"Human\"\n",
    "    elif fn[0:3] in (\"CPB\", \"CVR\"):\n",
    "        species = \"Human\"\n",
    "    else:\n",
    "        species = \"Unknown\"\n",
    "        # raise ValueError(f\"Couldn't find species for {fps}!\")\n",
    "\n",
    "    dataframe['filepath'].append(fps)\n",
    "    dataframe['species'].append(species)\n",
    "    \n",
    "    # track which file we're on\n",
    "    n_current += 1\n",
    "    print(f\"Processed file {n_current}/{n_files}: {fps}\")\n",
    "\n",
    "print(f\"FP: {len(dataframe['filepath'])}, SR: {len(dataframe['sr'])}, Spectrum: {len(dataframe['spectrum'])}, wf: {len(dataframe['wf'])}, freqs: {len(dataframe['freqs'])}, Species: {len(dataframe['species'])}\"), \n",
    "print(f\"Finished! Ignored {n_oral} mouth/oral files, {n_readme} README files, {n_tube} tube files, {n_earsoae} earsoae files, {n_supptone} suppression tone files\")\n",
    "print(f\"We kept {n_suppgood} good suppression files and {n_wf} waveform files.\")\n",
    "\n",
    "# # turn this into a pandas dataframe\n",
    "df = pd.DataFrame(dataframe)\n",
    "# save this as a parquet file for efficient dataframe storage (use pyarrow since the 'wf' column has different length lists)\n",
    "df.to_parquet(f'{folder}.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"Pre-2014 Data\"\n",
    "    \n",
    "# We'll build our dataframe by making a dictionary of lists and appending to them\n",
    "dataframe = {\n",
    "    'filepath': [],\n",
    "    'freqs': [],\n",
    "    'spectrum': [],\n",
    "    'wf': [],\n",
    "    'species': [],\n",
    "    'sr': [],\n",
    "}\n",
    "\n",
    "# First navigate to our directory\n",
    "directory_path = Path(main_path_str + folder)\n",
    "\n",
    "# track which file we're on\n",
    "n_files = sum(1 for _ in directory_path.rglob('*') if _.is_file())\n",
    "\n",
    "# track how many of each filetype we have\n",
    "n_current = 0\n",
    "n_readme = 0\n",
    "n_tube = 0\n",
    "n_earsoae = 0\n",
    "n_supptone = 0\n",
    "n_suppgood = 0\n",
    "n_wf = 0\n",
    "# now loop through all files in that collection\n",
    "for fp in directory_path.rglob('*'):\n",
    "    # Make sure it's a file\n",
    "    if fp.is_file() == False:  \n",
    "        continue\n",
    "    \n",
    "    # Get various versions of the filepath/filename\n",
    "    \n",
    "    # Cut off the beginning of the filepath since it's unnecessary for our dataframe (fps = file path shortened)\n",
    "    main_path = Path(main_path_str)\n",
    "    fps = str(fp.relative_to(main_path))\n",
    "    \n",
    "    # Also get subfolder (if applicable)\n",
    "    if len(fps.split(\"\\\\\")) > 1:\n",
    "        subfolder = fps.split(\"\\\\\")[1]\n",
    "    else:\n",
    "        subfolder = \"NA\"\n",
    "        \n",
    "    # Get the filename itself (without its containing folders), extension, and uppercase version\n",
    "    fn = fp.name\n",
    "    ext = fp.suffix\n",
    "    fnU = fn.upper()\n",
    "\n",
    "    # Treat different files differently based on keywords in filename\n",
    "    \n",
    "    if \"README\" in fnU or ext not in ('.txt' '.mat'):\n",
    "        # print(f\"Skipping {fps} -- README or wrong extension\")\n",
    "        n_readme += 1\n",
    "        continue\n",
    "    \n",
    "    elif \"TUBE\" in fnU:\n",
    "        # print(f\"Skipping {fps} -- Tube file\")\n",
    "        n_tube += 1\n",
    "        continue\n",
    "    \n",
    "    elif \"SUPP\" in fnU and \"SOAE\" in fnU:\n",
    "        if ext == '.txt':\n",
    "            data = np.loadtxt(fp)\n",
    "        else:\n",
    "            raise ValueError(f\"Supp file from {fps} isn't .txt!\")\n",
    "        try: \n",
    "            if data.shape[1] != 2:\n",
    "                raise RuntimeError(f\"Supp file from {fps} isn't two columns!\")\n",
    "        except:\n",
    "            raise(f\"Supp file from {fps} isn't 2D!\")\n",
    "        if has_supptone(data):\n",
    "            # plot_supp(fp)\n",
    "            print(f\"Skipping {fps} -- true suppression tone!\")\n",
    "            n_supptone += 1\n",
    "            if \"NOSUPP\" in fnU:\n",
    "                raise RuntimeError(f\"Our suppression tone detector is wrong! {fps} shouldn't have a suppression tone...\")\n",
    "            continue\n",
    "        else:\n",
    "            # pull out frequency axis and spectrum and add to dataframe dictionary\n",
    "            freqs = data[:, 0]\n",
    "            spectrum = data[:, 1]\n",
    "            dataframe['freqs'].append(freqs)\n",
    "            dataframe['spectrum'].append(spectrum)\n",
    "            # add a samplerate of 0 and an empty value to the waveform to fill the space\n",
    "            dataframe['sr'].append(0)\n",
    "            dataframe['wf'].append(None)\n",
    "            # record we got a good one\n",
    "            n_suppgood += 1\n",
    "    \n",
    "    elif (\"EAR\" in fnU and \"SOAE\" in fnU) and (\"WF\" not in fnU and \"WAVEFORM\" not in fnU and \"SUPP\" not in fnU):\n",
    "        print(f\"Skipping {fps} -- Chris can't say if good or not\")\n",
    "        n_earsoae += 1\n",
    "        continue\n",
    "    \n",
    "    elif \"WF\" in fnU or \"WAVEFORM\" in fnU:\n",
    "    # we must have a waveform if we got here\n",
    "        # Check if it's a .txt or .mat file\n",
    "        try:\n",
    "            if ext == '.mat':\n",
    "                mat = scipy.io.loadmat(fp)\n",
    "                if 'wf' in mat:\n",
    "                    wf = np.squeeze(mat['wf'])\n",
    "                else: \n",
    "                    print(f\"Not sure how to process {fps}\")\n",
    "            if ext == '.txt':\n",
    "                wf = np.loadtxt(fp)\n",
    "            # Let's make sure this waveform is a 1D array\n",
    "            if len(wf.shape) > 1:\n",
    "                raise RuntimeError(f\"Waveform from {fps} isn't 1D!\")\n",
    "            # add to the dataframe \n",
    "            dataframe['sr'].append(44100)\n",
    "            dataframe['wf'].append(wf)\n",
    "            # add empty values to the spectrum and freqs to fill the space\n",
    "            dataframe['freqs'].append(None)\n",
    "            dataframe['spectrum'].append(None)\n",
    "            n_wf += 1\n",
    "        except:\n",
    "            f\"Uh oh! Issue when loading {fps}\"\n",
    "    else:\n",
    "        raise RuntimeError(f\"UH OH {fps} didn't fall into any categories:\")\n",
    "        \n",
    "            \n",
    "            \n",
    "    # Get species\n",
    "    subfolder_species = subfolder.split(\" \")[0]\n",
    "    match subfolder_species:\n",
    "        case 'Geckos' | 'Lizards':\n",
    "            species = \"Lizard\"\n",
    "        case 'Tigers':\n",
    "            species = \"Tiger\"\n",
    "        case _:\n",
    "            species = subfolder_species\n",
    "\n",
    "    dataframe['filepath'].append(fps)\n",
    "    dataframe['species'].append(species)\n",
    "    \n",
    "    # track which file we're on\n",
    "    n_current += 1\n",
    "    print(f\"Processed file {n_current}/{n_files}: {fps}\")\n",
    "\n",
    "print(f\"FP: {len(dataframe['filepath'])}, SR: {len(dataframe['sr'])}, Spectrum: {len(dataframe['spectrum'])}, wf: {len(dataframe['wf'])}, freqs: {len(dataframe['freqs'])}, Species: {len(dataframe['species'])}\"), \n",
    "print(f\"Finished! Ignored {n_readme} README files, {n_tube} tube files, {n_earsoae} earsoae files, {n_supptone} suppression tone files\")\n",
    "print(f\"We kept {n_suppgood} good suppression files and {n_wf} waveform files.\")\n",
    "\n",
    "# turn this into a pandas dataframe\n",
    "df = pd.DataFrame(dataframe)\n",
    "# save this as a parquet file for efficient dataframe storage (use pyarrow since the 'wf' column has different length lists)\n",
    "df.to_parquet(f'{folder}.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"Extra Owl\"\n",
    "    \n",
    "# We'll build our dataframe by making a dictionary of lists and appending to them\n",
    "dataframe = {\n",
    "    'filepath': [],\n",
    "    'wf': [],  \n",
    "    'species': [],\n",
    "    'sr': [],\n",
    "}\n",
    "\n",
    "# First navigate to our directory\n",
    "directory_path = Path(main_path_str + folder)\n",
    "\n",
    "# track which file we're on\n",
    "n_files = sum(1 for _ in directory_path.rglob('*') if _.is_file())\n",
    "n_current=0\n",
    "\n",
    "# now loop through all files in that collection\n",
    "for fp in directory_path.rglob('*'):\n",
    "    # Check if it's a file\n",
    "    if fp.is_file():  \n",
    "        # Cut off the beginning of the filepath since it's unnecessary for our dataframe (fps = file path shortened)\n",
    "        main_path = Path(main_path_str)\n",
    "        fps = str(fp.relative_to(main_path))\n",
    "        \n",
    "        # Get the filename itself (without its containing folders)\n",
    "        fn = fp.name\n",
    "        # Also uppercase\n",
    "        fnU = fn.upper()  \n",
    "        \n",
    "        n_current += 1\n",
    "        print(f\"Processing file {n_current}/{n_files}\")\n",
    "        \n",
    "        # now we actually open the waveform here\n",
    "        # Check if it's a .txt or .mat file\n",
    "        try:\n",
    "            if fp.suffix == '.mat':\n",
    "                mat = scipy.io.loadmat(fp)\n",
    "                if 'wf' in mat:\n",
    "                    wf = np.squeeze(mat['wf'])\n",
    "                else: \n",
    "                    print(f\"Not sure how to process {fp}\")\n",
    "            if fp.suffix == '.txt':\n",
    "                wf = np.loadtxt(fp)\n",
    "            # Let's make sure this waveform is a 1D array\n",
    "            if len(wf.shape) > 1:\n",
    "                print(f\"Waveform from {fps} isn't 1D!\")\n",
    "        except:\n",
    "            f\"Uh oh! Issue when loading {fp}\"\n",
    "            \n",
    "        if str(fps).split(\"\\\\\")[1]=='Oldenberg Data (2013) (44.1kHz)':\n",
    "            sr = 44100\n",
    "            species = \"Owl\"\n",
    "        elif str(fps).split(\"\\\\\")[1]=='Pim owl files (48 kHz)':\n",
    "            sr = 48000\n",
    "            species = \"Owl\"\n",
    "        else:\n",
    "            print(\"UH OH WHERE ARE WE\")\n",
    "        \n",
    "            \n",
    "                \n",
    "        # add everything to our df dict\n",
    "        dataframe['filepath'].append(fps)\n",
    "        dataframe['wf'].append(wf)\n",
    "        dataframe['species'].append(species)\n",
    "        dataframe['sr'].append(sr)\n",
    "\n",
    "# turn this into a pandas dataframe\n",
    "df = pd.DataFrame(dataframe)\n",
    "# save this as a parquet file for efficient dataframe storage (use pyarrow since the 'wf' column has different length lists)\n",
    "df.to_parquet(f'{folder}.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"Lots of Data\"\n",
    "    \n",
    "# We'll build our dataframe by making a dictionary of lists and appending to them\n",
    "dataframe = {\n",
    "    'filepath': [],\n",
    "    'wf': [],  \n",
    "    'species': [],\n",
    "    'sr': [],\n",
    "}\n",
    "\n",
    "# First navigate to our directory\n",
    "directory_path = Path(main_path_str + folder)\n",
    "\n",
    "# track which file we're on\n",
    "n_files = sum(1 for _ in directory_path.rglob('*') if _.is_file())\n",
    "n_current=0\n",
    "\n",
    "# now loop through all files in that collection\n",
    "for fp in directory_path.rglob('*'):\n",
    "    # Check if it's a file\n",
    "    if fp.is_file():  \n",
    "        # Cut off the beginning of the filepath since it's unnecessary for our dataframe (fps = file path shortened)\n",
    "        main_path = Path(main_path_str)\n",
    "        fps = str(fp.relative_to(main_path))\n",
    "        \n",
    "        # Also get ubfolder (if applicable)\n",
    "        if len(fps.split(\"\\\\\")) > 1:\n",
    "            subfolder = fps.split(\"\\\\\")[1]\n",
    "        else:\n",
    "            subfolder = \"NA\"\n",
    "        \n",
    "        # Get the filename itself (without its containing folders)\n",
    "        fn = fp.name\n",
    "        \n",
    "        n_current += 1\n",
    "        print(f\"Processing file {n_current}/{n_files}\")\n",
    "\n",
    "        # now we actually open the waveform here\n",
    "        # Check if it's a .txt or .mat file\n",
    "        try:\n",
    "            if fp.suffix == '.mat':\n",
    "                mat = scipy.io.loadmat(fp)\n",
    "                if 'wf' in mat:\n",
    "                    wf = np.squeeze(mat['wf'])\n",
    "                else: \n",
    "                    print(f\"Not sure how to process {fp}\")\n",
    "            if fp.suffix == '.txt':\n",
    "                wf = np.loadtxt(fp)\n",
    "            # Let's make sure this waveform is a 1D array\n",
    "            if len(wf.shape) > 1:\n",
    "                print(f\"Waveform from {fps} isn't 1D!\")\n",
    "        except:\n",
    "            f\"Uh oh! Issue when loading {fp}\"\n",
    "            \n",
    "        # Get species\n",
    "        subfolder_species = subfolder.split(\".\")[3]\n",
    "        \n",
    "        match subfolder_species:\n",
    "            case 'tokay':\n",
    "                species = \"Tokay\"\n",
    "            case 'tegu':\n",
    "                species = \"Tegu\"\n",
    "            case 'human':\n",
    "                species = \"Human\"\n",
    "            case 'skink':\n",
    "                species = \"Skink\"\n",
    "            case 'owl':\n",
    "                species = \"Owl\"\n",
    "            case 'anolis':\n",
    "                species = \"Anolis\"\n",
    "            case 'ACsb42':\n",
    "                species = \"Anolis\"\n",
    "            case _:\n",
    "                print(f\"Couldn't find the species of {fn}\")\n",
    "        \n",
    "        # These all should have the standard sample rate\n",
    "        sr = 44100\n",
    "                \n",
    "        # add everything to our df dict\n",
    "        dataframe['filepath'].append(fps)\n",
    "        dataframe['wf'].append(wf)\n",
    "        dataframe['species'].append(species)\n",
    "        dataframe['sr'].append(sr)\n",
    "\n",
    "# turn this into a pandas dataframe\n",
    "df = pd.DataFrame(dataframe)\n",
    "# save this as a parquet file for efficient dataframe storage (use pyarrow since the 'wf' column has different length lists)\n",
    "df.to_parquet(f'{folder}.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder = \"Curated Data\"\n",
    "    \n",
    "# We'll build our dataframe by making a dictionary of lists and appending to them\n",
    "dataframe = {\n",
    "    'filepath': [],\n",
    "    'wf': [],  \n",
    "    'species': [],\n",
    "    'sr': [],\n",
    "}\n",
    "\n",
    "# First navigate to our directory\n",
    "directory_path = Path(main_path_str + subfolder)\n",
    "\n",
    "# track which file we're on\n",
    "n_files = sum(1 for _ in directory_path.rglob('*') if _.is_file())\n",
    "i=0\n",
    "\n",
    "# now loop through all files in that collection\n",
    "for fp in directory_path.rglob('*'):\n",
    "    # Check if it's a file\n",
    "    if fp.is_file():  \n",
    "        # Cut off the beginning of the filepath since it's unnecessary for our dataframe (fps = file path shortened)\n",
    "        main_path = Path(main_path_str)\n",
    "        fps = str(fp.relative_to(main_path))\n",
    "        \n",
    "        # Get the filename itself (without its containing folders)\n",
    "        \n",
    "        fn = fp.name\n",
    "        # print out which file we're on\n",
    "        i += 1\n",
    "        print(f\"Processing file {i}/{n_files}\")\n",
    "        \n",
    "        # now we actually open the waveform here\n",
    "        # Check if it's a .txt or .mat file\n",
    "        try:\n",
    "            if fp.suffix == '.mat':\n",
    "                mat = scipy.io.loadmat(fp)\n",
    "                if 'wf' in mat:\n",
    "                    wf = np.squeeze(mat['wf'])\n",
    "                else: \n",
    "                    print(f\"Not sure how to process {fp}\")\n",
    "            if fp.suffix == '.txt':\n",
    "                wf = np.loadtxt(fp)\n",
    "            # Let's make sure this waveform is a 1D array\n",
    "            if len(wf.shape) > 1:\n",
    "                print(f\"Waveform from {fps} isn't 1D!\")\n",
    "                continue\n",
    "        except:\n",
    "            f\"Uh oh! Issue when loading {fp}\"\n",
    "            \n",
    "            \n",
    "        # try and get the species name\n",
    "        fn_species = fn.split(\"_\")[0]\n",
    "        \n",
    "        match fn_species:\n",
    "            case 'anole':\n",
    "                species = \"Anolis\"\n",
    "            case 'cricket':\n",
    "                species = \"Cricket\"\n",
    "            case 'human':\n",
    "                species = \"Human\"\n",
    "            case 'owl':\n",
    "                species = \"Owl\"\n",
    "            case _:\n",
    "                species = \"\"\n",
    "        \n",
    "        # do some manual processing\n",
    "        if len(fn.split(\"_\")) > 1 and fn.split(\"_\")[1][0:3] == \"TAG\":\n",
    "            sr = 48000\n",
    "            species = \"Owl\"\n",
    "        else:\n",
    "            sr = 44100\n",
    "        \n",
    "        if len(fps.split(\"/\")) > 1 and fps.split(\"/\")[1] == \"Other\":\n",
    "            species = \"Unknown\"\n",
    "            sr = 0\n",
    "        \n",
    "        match fn:\n",
    "            case 'TT1learSOAEwf5.mat':\n",
    "                species = \"Tegu\"\n",
    "                sr = 44100\n",
    "            case 'TT3li.mat':\n",
    "                species = \"Tegu\"\n",
    "                sr = 44100\n",
    "            case 've10re01.mat':\n",
    "                species = \"Varanid\"\n",
    "            \n",
    "                \n",
    "        # add everything to our df dict\n",
    "        dataframe['filepath'].append(fps)\n",
    "        dataframe['wf'].append(wf)\n",
    "        dataframe['species'].append(species)\n",
    "        dataframe['sr'].append(sr)\n",
    "\n",
    "# turn this into a pandas dataframe\n",
    "df = pd.DataFrame(dataframe)\n",
    "# save this as a parquet file for efficient dataframe storage (use pyarrow since the 'wf' column has different length lists)\n",
    "df.to_parquet(f'{subfolder}.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
