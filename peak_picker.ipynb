{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, Dense, Concatenate, TimeDistributed, LSTM, Bidirectional, Layer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.autograph.experimental import do_not_convert\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from helper_funcs import gen_samples\n",
    "from scipy.fft import rfftfreq\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7637\n"
     ]
    }
   ],
   "source": [
    "# Load and split dataset\n",
    "\n",
    "# File paths\n",
    "transfer_directory_path = os.path.join(\"Data\", \"synth_transfer_df.parquet\")\n",
    "general_directory_path = os.path.join(\"Data\", \"synth_general_df.parquet\")\n",
    "\n",
    "# Load the dataframes\n",
    "synth_transfer_df = pd.read_parquet(transfer_directory_path)\n",
    "synth_general_df = pd.read_parquet(general_directory_path)\n",
    "\n",
    "# Ensure column names match\n",
    "assert list(synth_transfer_df.columns) == list(synth_general_df.columns), \"Column names do not match!\"\n",
    "\n",
    "# Add a dataset identifier for stratification\n",
    "synth_transfer_df['dataset'] = 'transfer'\n",
    "synth_general_df['dataset'] = 'general'\n",
    "\n",
    "# Combine the datasets\n",
    "df = pd.concat([synth_transfer_df, synth_general_df], axis=0)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Random state for reproducibility\n",
    "rs = 1\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "# Split each dataset (transfer and general) independently\n",
    "transfer_train, transfer_temp = train_test_split(\n",
    "    synth_transfer_df,\n",
    "    test_size=0.3,  # 30% of transfer dataset\n",
    "    stratify=synth_transfer_df['species'],  # Stratify based on species\n",
    "    random_state=rs\n",
    ")\n",
    "\n",
    "general_train, general_temp = train_test_split(\n",
    "    synth_general_df,\n",
    "    test_size=0.3,  # 30% of general dataset\n",
    "    stratify=synth_general_df['species'],  # Stratify based on species\n",
    "    random_state=rs\n",
    ")\n",
    "\n",
    "# Combine the training datasets from transfer and general\n",
    "train_df = pd.concat([transfer_train, general_train], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Split temp datasets (transfer and general) into test and validation\n",
    "transfer_test, transfer_val = train_test_split(\n",
    "    transfer_temp,\n",
    "    test_size=0.5,  # Split evenly into test and validation\n",
    "    stratify=transfer_temp['species'],\n",
    "    random_state=rs + 1\n",
    ")\n",
    "\n",
    "general_test, general_val = train_test_split(\n",
    "    general_temp,\n",
    "    test_size=0.5,  # Split evenly into test and validation\n",
    "    stratify=general_temp['species'],\n",
    "    random_state=rs + 1\n",
    ")\n",
    "\n",
    "# Combine test and validation datasets from transfer and general\n",
    "test_df = pd.concat([transfer_test, general_test], axis=0).reset_index(drop=True)\n",
    "val_df = pd.concat([transfer_val, general_val], axis=0).reset_index(drop=True)\n",
    "\n",
    "# # Verify distribution of species and datasets\n",
    "# print(\"Training dataset:\")\n",
    "# print(train_df['species'].value_counts())\n",
    "# print(train_df['dataset'].value_counts())\n",
    "\n",
    "# print(\"\\nValidation dataset:\")\n",
    "# print(val_df['species'].value_counts())\n",
    "# print(val_df['dataset'].value_counts())\n",
    "\n",
    "# print(\"\\nTest dataset:\")\n",
    "# print(test_df['species'].value_counts())\n",
    "# print(test_df['dataset'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Training Samples\n",
      "Generating Test Samples\n",
      "Generating Validation Samples\n"
     ]
    }
   ],
   "source": [
    "# Prepare samples\n",
    "print(\"Generating Training Samples\")\n",
    "X_train, y_train, mins_maxes_train, isolated_peaks_train = gen_samples(train_df)\n",
    "print(\"Generating Test Samples\")\n",
    "X_test, y_test, mins_maxes_test, isolated_peaks_test = gen_samples(test_df)\n",
    "print(\"Generating Validation Samples\")\n",
    "X_val, y_val, mins_maxes_val, isolated_peaks_val = gen_samples(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Crop num samples for testing\n",
    "# M = 1000\n",
    "# X_train = X_train[:M, :]\n",
    "# X_val = X_val[:M, :]\n",
    "# X_test = X_test[:M, :]\n",
    "\n",
    "# y_train = y_train[:M, :, :]\n",
    "# y_val = y_val[:M, :, :]\n",
    "# y_test = y_test[:M, :, :]\n",
    "\n",
    "# isolated_peaks_val = isolated_peaks_val[:M, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand axes for conv layers\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_val = np.expand_dims(X_val, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=3\n",
    "peak_encourage=1\n",
    "include_LSTM=False\n",
    "epochs = 1\n",
    "lr = 0.001\n",
    "model_version = f\"V1_k-{k}_PE-{peak_encourage}_LSTM-{include_LSTM}_Epochs-{epochs}_LR-{lr}\"\n",
    "batch_size = 32\n",
    "patience = 15\n",
    "threshold_list = [0.3, 0.4, 0.5, 0.6, 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom loss and metric callbacks\n",
    "def custom_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom loss function using predictions and weights.\n",
    "    \"\"\"\n",
    "    # Compute binary cross-entropy loss\n",
    "    bce_loss = tf.keras.backend.binary_crossentropy(y_true[:, :, 0], y_pred[:, :, 0])  # Shape (batch_size, N)\n",
    "\n",
    "    # prom = y_true[:, :, 2] is the 3rd node label, shape (batch_size, N)\n",
    "    # If prom < 0, weight is 1 (weight of BCE loss for non-peak bins), else apply weight_func\n",
    "    weights = tf.where(y_true[:, :, 2] < 0, tf.ones_like(y_true[:, :, 2]), peak_encourage/(1+tf.exp(k-y_true[:, :, 2])))  \n",
    "    # Apply weights\n",
    "    weighted_bce_loss = bce_loss * weights  # Shape (batch_size, bins_per_sample)\n",
    "\n",
    "    # Average loss across all samples and bins\n",
    "    total_loss = tf.reduce_mean(weighted_bce_loss)  # Scalar\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def peak_counting_error(isolated_peaks, predictions, threshold_list, verbose=False):\n",
    "    # Just grab the labels since we're ignoring width and height\n",
    "    predictions = predictions[:, :, 0]\n",
    "    M = isolated_peaks.shape[0] # Number of samples\n",
    "    assert M == predictions.shape[0], \"Mismatch in number of samples!\"\n",
    "    best_error = 10000  # Initial large value for minimizing error\n",
    "    best_thresh = None\n",
    "    for thresh in threshold_list:\n",
    "        current_error = 0\n",
    "        val_predictions_snapped = (predictions > thresh).astype(int)\n",
    "        \n",
    "        for row in range(M):\n",
    "            predictions_row = val_predictions_snapped[row, :]\n",
    "            isolated_labels_row = isolated_peaks[row, :]\n",
    "            \n",
    "            # We want to go along the predictions row, and find continuous chunks of 1s and 0s.\n",
    "            # Every time a chunk ends, we then check how many peaks were truly in that chunk (by counting the 1s in those indices in isolated_labels_row)\n",
    "            # We then add the square of the differences between the predicted number of peaks and the actual number of peaks to total_error\n",
    "            # The predicted number of peaks in a chunk of 1s is always 1, and the predicted number of peaks in a chunk of 0s is always 0.\n",
    "            \n",
    "            # Track the current chunk\n",
    "            current_chunk_value = predictions_row[0]\n",
    "            current_chunk_start = 0\n",
    "\n",
    "            for idx in range(1, len(predictions_row) + 1):  # +1 to handle the last chunk\n",
    "                if idx == len(predictions_row) or predictions_row[idx] != current_chunk_value:\n",
    "                    # Chunk ends here\n",
    "                    chunk_end = idx\n",
    "                    chunk_labels = isolated_labels_row[current_chunk_start:chunk_end]\n",
    "                    \n",
    "                    # Predicted peaks for this chunk\n",
    "                    predicted_peaks = current_chunk_value\n",
    "                    # Actual peaks for this chunk\n",
    "                    actual_peaks = int(chunk_labels.sum())  # Count the 1s in the chunk\n",
    "                    \n",
    "                    # Add squared error to total_error\n",
    "                    current_error += (predicted_peaks - actual_peaks) ** 2\n",
    "                    \n",
    "                    # Start a new chunk\n",
    "                    current_chunk_value = predictions_row[idx] if idx < len(predictions_row) else None\n",
    "                    current_chunk_start = idx\n",
    "        \n",
    "        current_error = current_error / M\n",
    "        if verbose:\n",
    "            print(f\"Peak counting error for threshold {thresh}: {current_error}\")\n",
    "        # Update the best threshold if this one performs better\n",
    "        if current_error < best_error:\n",
    "            best_error = current_error\n",
    "            best_thresh = thresh\n",
    "    if verbose:\n",
    "        print(f\"Best threshold: {best_thresh}, Best Peak Counting Error: {best_error}\")\n",
    "    return best_error, best_thresh\n",
    "        \n",
    "\n",
    "class ValidationMetricCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data, metric_name=\"peak_counting_error\"):\n",
    "        super(ValidationMetricCallback, self).__init__()\n",
    "        self.validation_data = validation_data\n",
    "        self.metric_name = metric_name\n",
    "    \n",
    "    @do_not_convert\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_x, (val_y, isolated_peaks_val) = self.validation_data  # Unpack extra labels\n",
    "        val_predictions = self.model.predict(val_x, verbose=0)\n",
    "        val_predictions = val_predictions[:, :, 0]\n",
    "        M = tf.shape(isolated_peaks_val)[0]  # Number of samples\n",
    "        tf.assert_equal(M, tf.shape(val_predictions)[0], message=\"Mismatch in number of samples!\")\n",
    "        \n",
    "        thresholds = tf.constant(threshold_list, dtype=tf.float32)\n",
    "        best_error = tf.constant(1e10, dtype=tf.float32)  # Initial large value for minimizing error\n",
    "        best_thresh = tf.constant(0.0, dtype=tf.float32)\n",
    "\n",
    "        \n",
    "        def calculate_error(thresh):\n",
    "            val_predictions_snapped = tf.cast(val_predictions > thresh, tf.int32)\n",
    "\n",
    "            def process_row(row_idx):\n",
    "                predictions_row = val_predictions_snapped[row_idx]\n",
    "                isolated_labels_row = isolated_peaks_val[row_idx]\n",
    "\n",
    "                chunk_boundaries = tf.concat([[0], tf.where(tf.not_equal(predictions_row[:-1], predictions_row[1:]))[:, 0] + 1, [tf.size(predictions_row)]], axis=0)\n",
    "                chunk_start_indices = chunk_boundaries[:-1]\n",
    "                chunk_end_indices = chunk_boundaries[1:]\n",
    "\n",
    "                def process_chunk(start, end):\n",
    "                    chunk_labels = isolated_labels_row[start:end]\n",
    "                    predicted_peaks = tf.cast(predictions_row[start], tf.float32)  # Cast to float32\n",
    "                    actual_peaks = tf.cast(tf.reduce_sum(chunk_labels), tf.float32)  # Cast to float32\n",
    "                    return tf.square(predicted_peaks - actual_peaks)\n",
    "\n",
    "                squared_errors = tf.map_fn(\n",
    "                    lambda indices: process_chunk(indices[0], indices[1]),\n",
    "                    (chunk_start_indices, chunk_end_indices),\n",
    "                    fn_output_signature=tf.float32\n",
    "                )\n",
    "                return tf.reduce_sum(squared_errors)\n",
    "\n",
    "            total_error = tf.map_fn(process_row, tf.range(M), fn_output_signature=tf.float32)\n",
    "            return tf.reduce_mean(total_error)\n",
    "\n",
    "        def update_best(thresh, current_error, best_error, best_thresh):\n",
    "            better = current_error < best_error\n",
    "            return tf.cond(\n",
    "                better,\n",
    "                lambda: (current_error, thresh),\n",
    "                lambda: (best_error, best_thresh)\n",
    "            )\n",
    "\n",
    "        for thresh in thresholds:\n",
    "            current_error = calculate_error(thresh)\n",
    "            best_error, best_thresh = update_best(thresh, current_error, best_error, best_thresh)\n",
    "\n",
    "        # Round the best_thresh to 3 decimal places\n",
    "        rounded_best_thresh = tf.round(best_thresh * 1000) / 1000.0  # Rounds to 3 decimal places\n",
    "    \n",
    "        # Add space before printing the custom output\n",
    "        tf.print(\"\\n--------------------------------------------\")\n",
    "        tf.print(f\"Best threshold: {rounded_best_thresh}, Best Peak Counting Error: {best_error}\")\n",
    "        tf.print(\"--------------------------------------------\\n\")\n",
    "\n",
    "        logs[self.metric_name] = best_error\n",
    "\n",
    "\n",
    "class TimeHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epoch_times = []  # List to store time per epoch\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()  # Record start time of epoch\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_time = time.time() - self.epoch_start_time  # Calculate epoch duration\n",
    "        self.epoch_times.append(epoch_time)  # Save to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 04:49:04.478105: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-12-12 04:49:04.478153: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyter-dkog58yj): /proc/driver/nvidia/version does not exist\n",
      "2024-12-12 04:49:04.479124: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"V1_k-3_PE-1_LSTM-False_Epochs-1_LR-0.001\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"V1_k-3_PE-1_LSTM-False_Epochs-1_LR-0.001\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │ Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │ Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │ Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │ Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │ Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv_101 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">816</span> │ Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv_149 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │ Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv_201 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">404</span> │ Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Inception_Concat    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">154</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Conv_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Conv_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ Conv_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ Conv_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ Conv_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ Conv_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ Conv_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ Conv_101[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ Conv_149[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ Conv_201[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Dense_64            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,920</span> │ Inception_Concat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Dense_32A           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ Dense_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ LSTM                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,272</span> │ Dense_32A[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Dense_32B           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ LSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Dense_16            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ Dense_32B[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Output              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │ Dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv_3 (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m, \u001b[38;5;34m4\u001b[0m)   │         \u001b[38;5;34m16\u001b[0m │ Input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv_5 (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │         \u001b[38;5;34m48\u001b[0m │ Input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv_9 (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │        \u001b[38;5;34m160\u001b[0m │ Input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv_15 (\u001b[38;5;33mConv1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ Input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv_31 (\u001b[38;5;33mConv1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │      \u001b[38;5;34m1,024\u001b[0m │ Input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv_55 (\u001b[38;5;33mConv1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │      \u001b[38;5;34m1,792\u001b[0m │ Input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv_71 (\u001b[38;5;33mConv1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │      \u001b[38;5;34m1,152\u001b[0m │ Input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv_101 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │        \u001b[38;5;34m816\u001b[0m │ Input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv_149 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m, \u001b[38;5;34m4\u001b[0m)   │        \u001b[38;5;34m600\u001b[0m │ Input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv_201 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m, \u001b[38;5;34m2\u001b[0m)   │        \u001b[38;5;34m404\u001b[0m │ Input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Inception_Concat    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m, \u001b[38;5;34m154\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ Conv_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Conv_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ Conv_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ Conv_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ Conv_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ Conv_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ Conv_71[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ Conv_101[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ Conv_149[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ Conv_201[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Dense_64            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │      \u001b[38;5;34m9,920\u001b[0m │ Inception_Concat… │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Dense_32A           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │      \u001b[38;5;34m2,080\u001b[0m │ Dense_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ LSTM                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │      \u001b[38;5;34m6,272\u001b[0m │ Dense_32A[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Dense_32B           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │      \u001b[38;5;34m1,056\u001b[0m │ LSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Dense_16            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │        \u001b[38;5;34m528\u001b[0m │ Dense_32B[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Output              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m, \u001b[38;5;34m3\u001b[0m)   │         \u001b[38;5;34m51\u001b[0m │ Dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,431</span> (103.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,431\u001b[0m (103.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,431</span> (103.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,431\u001b[0m (103.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the input length / number of frequency bins (N)\n",
    "N = 8192\n",
    "include_LSTM = True\n",
    "# Input layer\n",
    "input_layer = Input(shape=(N, 1), name=\"Input\")\n",
    "# Inception-like layer with 1D convolutions\n",
    "convs = []\n",
    "# We'll base our kernel choices on the hwhm distribution of the peaks. \n",
    "# Thin peaks are in 3Hz-10Hz range --> 5-15 bins\n",
    "# Wide peaks are in 10Hz-100Hz range --> 15-149 bins\n",
    "# We choose filters at a range of scales, odd (to facilitate being cenetered around a peak)\n",
    "# and we want more filters for the medium-small range since there are more peaks at this scale.\n",
    "# Otherwise largely arbitrarily.\n",
    "kernels = [(3, 4), (5, 8), (9, 16), (15, 32), (31, 32), (55, 32), (71, 16), (101, 8), (149, 4), (201, 2)]\n",
    "for kernel_size, num_filters in kernels:\n",
    "    convs.append(Conv1D(num_filters, kernel_size=kernel_size, activation='relu', padding='same', name=f\"Conv_{kernel_size}\")(input_layer))\n",
    "\n",
    "# Concatenate the outputs of all convolutional layers\n",
    "concat_layer = Concatenate(name=\"Inception_Concat\")(convs)\n",
    "\n",
    "# Time Distributed Dense Layers\n",
    "td_dense64 = TimeDistributed(Dense(64, activation='relu'), name=\"Dense_64\")(concat_layer)\n",
    "td_dense32A = TimeDistributed(Dense(32, activation='relu'), name=\"Dense_32A\")(td_dense64)\n",
    "if include_LSTM:\n",
    "    bd_LSTM = Bidirectional(LSTM(16, return_sequences=True), name=\"LSTM\")(td_dense32A)\n",
    "    td_dense32B = TimeDistributed(Dense(32, activation='relu'), name=\"Dense_32B\")(bd_LSTM)\n",
    "else:\n",
    "    td_dense32B = TimeDistributed(Dense(32, activation='relu'), name=\"Dense_32B\")(td_dense32A)\n",
    "td_dense16 = TimeDistributed(Dense(16, activation='relu'), name=\"Dense_16\")(td_dense32B)\n",
    "\n",
    "# Final layer with 3 outputs per input bin\n",
    "output_layer = TimeDistributed(Dense(3, activation='sigmoid'), name=\"Output\")(td_dense16)\n",
    "\n",
    "# Define the model to output both predictions and weights\n",
    "model = tf.keras.Model(\n",
    "    inputs=input_layer, \n",
    "    outputs=output_layer,  # Explicitly define both outputs\n",
    "    name=model_version\n",
    ")\n",
    "\n",
    "\n",
    "# Compile the model (lambda function in loss to allow for prominences to be passed in as weights)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "    # loss=lambda y_true, y_pred: custom_loss(y_true, y_pred, weights)\n",
    "    loss=custom_loss\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 0.3318\n",
      "--------------------------------------------\n",
      "Best threshold: 0.30000001192092896, Best Peak Counting Error: 389.51800537109375\n",
      "--------------------------------------------\n",
      "\n",
      "32/32 [==============================] - 65s 2s/step - loss: 0.3318 - val_loss: 0.0256 - peak_counting_error: 389.5180\n",
      "Execution time: 64.89 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_path = os.path.join(\"PP Models\", f\"{model_version}.keras\")\n",
    "epoch_model_path = os.path.join(\"PP Models (All Epochs)\", f\"{model_version} - \", \"epoch{epoch:02d}.keras\")\n",
    "\n",
    "time_callback = TimeHistory()\n",
    "\n",
    "# Add callbacks for better training\n",
    "callbacks = [\n",
    "    # ValidationMetricCallback(validation_data=(X_val, (y_val, isolated_peaks_val)), metric_name=\"peak_counting_error\"),\n",
    "    # EarlyStopping(monitor=\"peak_counting_error\", patience=patience, restore_best_weights=True, verbose=1),  # Stop if no improvement for {patience} epochs\n",
    "    ModelCheckpoint(model_path, save_best_only=True, monitor=\"val_loss\"),  # Save the best model\n",
    "    ModelCheckpoint(epoch_model_path, save_best_only=False, monitor=\"peak_counting_error\"),  # Save all models model\n",
    "    time_callback\n",
    "]\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "dataset = dataset.shuffle(buffer_size=1000).batch(batch_size)\n",
    "\n",
    "# Validation dataset\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batch_size)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs,        # Number of epochs\n",
    "    batch_size=batch_size,  # Batch size\n",
    "    callbacks=callbacks,    # Add callbacks for early stopping and checkpointing\n",
    "    verbose=1               # Verbose output\n",
    ")\n",
    "\n",
    "history.history['epoch_times'] = time_callback.epoch_times\n",
    "\n",
    "with open(os.path.join(\"PP Model Histories\", f\"{model_version}_history.pkl\"), 'wb') as file:\n",
    "    pickle.dump(history.history, file)\n",
    "    \n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Execution time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File not found: filepath=PP Model\\V1_k-3_PE-1_LSTM-False_Epochs-1_LR-0.001.keras. Please ensure the file is an accessible `.keras` zip file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# CHECKING PREDICTIONS\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPP Model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_version\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.keras\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcustom_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_loss\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m val_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)  \u001b[38;5;66;03m# Predicted probabilities or binary values\u001b[39;00m\n\u001b[0;32m      4\u001b[0m sample_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m55\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:200\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[0;32m    197\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[0;32m    198\u001b[0m     )\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    204\u001b[0m     )\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmight have a different name).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: File not found: filepath=PP Model\\V1_k-3_PE-1_LSTM-False_Epochs-1_LR-0.001.keras. Please ensure the file is an accessible `.keras` zip file."
     ]
    }
   ],
   "source": [
    "# CHECKING PREDICTIONS\n",
    "model = load_model(os.path.join(\"PP Model\", f\"{model_version}.keras\"), custom_objects={\"custom_loss\": custom_loss})\n",
    "val_pred = model.predict(X_val)  # Predicted probabilities or binary values\n",
    "sample_idx = 55\n",
    "# Get spectrum (last 0 is just becuase this has shape (n_Samples, bins, 1))\n",
    "spectrum = X_val[sample_idx, :, 0]\n",
    "# Get predictions (last 0 is because we want \n",
    "predicted_peaks = val_pred[sample_idx, :, 0] \n",
    "print(predicted_peaks)\n",
    "print(X_val[sample_idx, :, 0])\n",
    "\n",
    "\n",
    "# Frequency axis for the spectrum\n",
    "f = rfftfreq(32768, 1/44100)[0:8192]\n",
    "\n",
    "# Plot the spectrum\n",
    "plt.plot(f, spectrum, label='Original Spectrum')\n",
    "\n",
    "# Add colors depending on percentage of prediction\n",
    "scatter = plt.scatter(f, spectrum, c=predicted_peaks, cmap='viridis', s=20)\n",
    "\n",
    "# Add color bar\n",
    "plt.colorbar(scatter, label='Predicted Peaks Value')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Spectrum with Scatter Points Colored by Predicted Peaks Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM = False, k = 0, PE = 15, Best Val Threshold: 0.9, Best Epoch: 25, Test Error: 6.39005\n",
      "Execution time per model: 69.88 seconds\n",
      "LSTM = False, k = 0, PE = 5, Best Val Threshold: 0.8, Best Epoch: 24, Test Error: 4.74084\n",
      "Execution time per model: 57.48 seconds\n",
      "LSTM = False, k = 0, PE = 10, Best Val Threshold: 0.7, Best Epoch: 24, Test Error: 5.25305\n",
      "Execution time per model: 57.09 seconds\n",
      "LSTM = False, k = 0, PE = 1, Best Val Threshold: 0.4, Best Epoch: 24, Test Error: 5.02094\n",
      "Execution time per model: 54.88 seconds\n",
      "LSTM = False, k = 3, PE = 15, Best Val Threshold: 0.2, Best Epoch: 25, Test Error: 6.63962\n",
      "Execution time per model: 55.21 seconds\n",
      "LSTM = False, k = 3, PE = 5, Best Val Threshold: 0.1, Best Epoch: 25, Test Error: 5.05061\n",
      "Execution time per model: 54.92 seconds\n",
      "LSTM = False, k = 3, PE = 10, Best Val Threshold: 0.01, Best Epoch: 24, Test Error: 437.50698\n",
      "Execution time per model: 52.01 seconds\n",
      "LSTM = False, k = 3, PE = 1, Best Val Threshold: 0.05, Best Epoch: 25, Test Error: 6.63002\n",
      "Execution time per model: 53.80 seconds\n",
      "LSTM = True, k = 0, PE = 15, Best Val Threshold: 0.6, Best Epoch: 25, Test Error: 1.9712\n",
      "Execution time per model: 107.72 seconds\n",
      "LSTM = True, k = 0, PE = 5, Best Val Threshold: 0.7, Best Epoch: 25, Test Error: 3.27051\n",
      "Execution time per model: 110.23 seconds\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "No file or directory found at PP Models (All Epochs)/V1_k-0_PE-10_LSTM-True_Epochs-25_LR-0.001 - epoch 24.keras",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m best_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Preload all models for the current hyperparameter combination\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     17\u001b[0m     i: load_model(\n\u001b[1;32m     18\u001b[0m         os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPP Models (All Epochs)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV1_k-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_PE-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpeak_encourage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_LSTM-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minclude_LSTM\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Epochs-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_LR-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     19\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: custom_loss}\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(min_epoch, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m }\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(min_epoch, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):  \u001b[38;5;66;03m# Use epochs instead of hardcoding 25\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     model_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV1_k-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_PE-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpeak_encourage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_LSTM-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minclude_LSTM\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Epochs-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_LR-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m best_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Preload all models for the current hyperparameter combination\u001b[39;00m\n\u001b[1;32m     16\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 17\u001b[0m     i: \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPP Models (All Epochs)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mV1_k-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mk\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_PE-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpeak_encourage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_LSTM-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43minclude_LSTM\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_Epochs-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_LR-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlr\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m - epoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m02\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.keras\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcustom_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_loss\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(min_epoch, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m }\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(min_epoch, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):  \u001b[38;5;66;03m# Use epochs instead of hardcoding 25\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     model_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV1_k-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_PE-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpeak_encourage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_LSTM-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minclude_LSTM\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Epochs-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_LR-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/fs/ess/PAS2038/PHYSICS_5680_OSU/jupyter/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/fs/ess/PAS2038/PHYSICS_5680_OSU/jupyter/lib/python3.9/site-packages/keras/saving/save.py:226\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 226\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m    227\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m         )\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m    232\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[1;32m    233\u001b[0m         )\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at PP Models (All Epochs)/V1_k-0_PE-10_LSTM-True_Epochs-25_LR-0.001 - epoch 24.keras"
     ]
    }
   ],
   "source": [
    "# Calculate Peak Counting Error for all hyperparameter combos\n",
    "epochs = 25\n",
    "min_epoch = 24\n",
    "threshold_list = [0.01, 0.03, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "lr = 0.001\n",
    "\n",
    "for include_LSTM in [False, True]:\n",
    "    for k in [0, 3]:\n",
    "        for peak_encourage in [15, 5, 10, 1]:\n",
    "            start_time = time.time()\n",
    "            all_epoch_best_thresh = 0\n",
    "            all_epoch_best_error = np.inf\n",
    "            best_epoch = 0\n",
    "\n",
    "            # Preload all models for the current hyperparameter combination\n",
    "            models = {\n",
    "                i: load_model(\n",
    "                    os.path.join(\"PP Models (All Epochs)\", f\"V1_k-{k}_PE-{peak_encourage}_LSTM-{include_LSTM}_Epochs-{epochs}_LR-{lr} - epoch {i:02}.keras\"),\n",
    "                    custom_objects={\"custom_loss\": custom_loss}\n",
    "                )\n",
    "                for i in range(min_epoch, epochs + 1)\n",
    "            }\n",
    "\n",
    "            for i in range(min_epoch, epochs + 1):  # Use epochs instead of hardcoding 25\n",
    "                model_version = f\"V1_k-{k}_PE-{peak_encourage}_LSTM-{include_LSTM}_Epochs-{epochs}_LR-{lr} - epoch {i:02}\"\n",
    "                model = models[i]  # Use preloaded model\n",
    "                val_pred = model.predict(X_val, verbose=0)  # Predicted probabilities\n",
    "                best_error, best_thresh = peak_counting_error(isolated_peaks_val, val_pred, threshold_list=threshold_list)\n",
    "\n",
    "                if best_error < all_epoch_best_error:\n",
    "                    all_epoch_best_error = best_error\n",
    "                    all_epoch_best_thresh = best_thresh\n",
    "                    best_epoch = i\n",
    "\n",
    "            # Load the best model using the preloaded dictionary\n",
    "            best_model = models[best_epoch]\n",
    "            test_pred = best_model.predict(X_test, verbose=0)  # Predicted probabilities\n",
    "            test_error, test_thresh = peak_counting_error(isolated_peaks_test, test_pred, threshold_list=[all_epoch_best_thresh])\n",
    "            assert test_thresh == all_epoch_best_thresh\n",
    "            print(f\"LSTM = {include_LSTM}, k = {k}, PE = {peak_encourage}, Best Val Threshold: {round(all_epoch_best_thresh, 2)}, Best Epoch: {best_epoch}, Test Error: {round(test_error, 5)}\")\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"Execution time per model: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "7637\n",
      "Generating Training Samples\n",
      "Generating Test Samples\n",
      "Generating Validation Samples\n",
      "LSTM = False, k = 0, PE = 15, Best Val Threshold: 0.9, Best Epoch: 25, Test Error: 6.39005\n",
      "Execution time per model: 51.83 seconds\n",
      "LSTM = False, k = 0, PE = 5, Best Val Threshold: 0.8, Best Epoch: 24, Test Error: 4.74084\n",
      "Execution time per model: 45.08 seconds\n",
      "LSTM = False, k = 0, PE = 10, Best Val Threshold: 0.7, Best Epoch: 24, Test Error: 5.25305\n",
      "Execution time per model: 45.42 seconds\n",
      "LSTM = False, k = 0, PE = 1, Best Val Threshold: 0.4, Best Epoch: 24, Test Error: 5.02094\n",
      "Execution time per model: 44.91 seconds\n",
      "LSTM = False, k = 3, PE = 15, Best Val Threshold: 0.2, Best Epoch: 25, Test Error: 6.63962\n",
      "Execution time per model: 44.15 seconds\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, Dense, Concatenate, TimeDistributed, LSTM, Bidirectional, Layer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.autograph.experimental import do_not_convert\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from helper_funcs import gen_samples\n",
    "from scipy.fft import rfftfreq\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Load and split dataset\n",
    "\n",
    "# File paths\n",
    "transfer_directory_path = os.path.join(\"Data\", \"synth_transfer_df.parquet\")\n",
    "general_directory_path = os.path.join(\"Data\", \"synth_general_df.parquet\")\n",
    "\n",
    "# Load the dataframes\n",
    "synth_transfer_df = pd.read_parquet(transfer_directory_path)\n",
    "synth_general_df = pd.read_parquet(general_directory_path)\n",
    "\n",
    "# Ensure column names match\n",
    "assert list(synth_transfer_df.columns) == list(synth_general_df.columns), \"Column names do not match!\"\n",
    "\n",
    "# Add a dataset identifier for stratification\n",
    "synth_transfer_df['dataset'] = 'transfer'\n",
    "synth_general_df['dataset'] = 'general'\n",
    "\n",
    "# Combine the datasets\n",
    "df = pd.concat([synth_transfer_df, synth_general_df], axis=0)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Random state for reproducibility\n",
    "rs = 1\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "# Split each dataset (transfer and general) independently\n",
    "transfer_train, transfer_temp = train_test_split(\n",
    "    synth_transfer_df,\n",
    "    test_size=0.3,  # 30% of transfer dataset\n",
    "    stratify=synth_transfer_df['species'],  # Stratify based on species\n",
    "    random_state=rs\n",
    ")\n",
    "\n",
    "general_train, general_temp = train_test_split(\n",
    "    synth_general_df,\n",
    "    test_size=0.3,  # 30% of general dataset\n",
    "    stratify=synth_general_df['species'],  # Stratify based on species\n",
    "    random_state=rs\n",
    ")\n",
    "\n",
    "# Combine the training datasets from transfer and general\n",
    "train_df = pd.concat([transfer_train, general_train], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Split temp datasets (transfer and general) into test and validation\n",
    "transfer_test, transfer_val = train_test_split(\n",
    "    transfer_temp,\n",
    "    test_size=0.5,  # Split evenly into test and validation\n",
    "    stratify=transfer_temp['species'],\n",
    "    random_state=rs + 1\n",
    ")\n",
    "\n",
    "general_test, general_val = train_test_split(\n",
    "    general_temp,\n",
    "    test_size=0.5,  # Split evenly into test and validation\n",
    "    stratify=general_temp['species'],\n",
    "    random_state=rs + 1\n",
    ")\n",
    "\n",
    "# Combine test and validation datasets from transfer and general\n",
    "test_df = pd.concat([transfer_test, general_test], axis=0).reset_index(drop=True)\n",
    "val_df = pd.concat([transfer_val, general_val], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Prepare samples\n",
    "print(\"Generating Training Samples\")\n",
    "X_train, y_train, mins_maxes_train, isolated_peaks_train = gen_samples(train_df)\n",
    "print(\"Generating Test Samples\")\n",
    "X_test, y_test, mins_maxes_test, isolated_peaks_test = gen_samples(test_df)\n",
    "print(\"Generating Validation Samples\")\n",
    "X_val, y_val, mins_maxes_val, isolated_peaks_val = gen_samples(val_df)\n",
    "\n",
    "# Expand axes for conv layers\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_val = np.expand_dims(X_val, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "\n",
    "# Define custom loss and metric callbacks\n",
    "def custom_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom loss function using predictions and weights.\n",
    "    \"\"\"\n",
    "    # Compute binary cross-entropy loss\n",
    "    bce_loss = tf.keras.backend.binary_crossentropy(y_true[:, :, 0], y_pred[:, :, 0])  # Shape (batch_size, N)\n",
    "\n",
    "    # prom = y_true[:, :, 2] is the 3rd node label, shape (batch_size, N)\n",
    "    # If prom < 0, weight is 1 (weight of BCE loss for non-peak bins), else apply weight_func\n",
    "    weights = tf.where(y_true[:, :, 2] < 0, tf.ones_like(y_true[:, :, 2]), peak_encourage/(1+tf.exp(k-y_true[:, :, 2])))  \n",
    "    # Apply weights\n",
    "    weighted_bce_loss = bce_loss * weights  # Shape (batch_size, bins_per_sample)\n",
    "\n",
    "    # Average loss across all samples and bins\n",
    "    total_loss = tf.reduce_mean(weighted_bce_loss)  # Scalar\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def peak_counting_error(isolated_peaks, predictions, threshold_list, verbose=False):\n",
    "    # Just grab the labels since we're ignoring width and height\n",
    "    predictions = predictions[:, :, 0]\n",
    "    M = isolated_peaks.shape[0] # Number of samples\n",
    "    assert M == predictions.shape[0], \"Mismatch in number of samples!\"\n",
    "    best_error = 10000  # Initial large value for minimizing error\n",
    "    best_thresh = None\n",
    "    for thresh in threshold_list:\n",
    "        current_error = 0\n",
    "        val_predictions_snapped = (predictions > thresh).astype(int)\n",
    "        \n",
    "        for row in range(M):\n",
    "            predictions_row = val_predictions_snapped[row, :]\n",
    "            isolated_labels_row = isolated_peaks[row, :]\n",
    "            \n",
    "            # We want to go along the predictions row, and find continuous chunks of 1s and 0s.\n",
    "            # Every time a chunk ends, we then check how many peaks were truly in that chunk (by counting the 1s in those indices in isolated_labels_row)\n",
    "            # We then add the square of the differences between the predicted number of peaks and the actual number of peaks to total_error\n",
    "            # The predicted number of peaks in a chunk of 1s is always 1, and the predicted number of peaks in a chunk of 0s is always 0.\n",
    "            \n",
    "            # Track the current chunk\n",
    "            current_chunk_value = predictions_row[0]\n",
    "            current_chunk_start = 0\n",
    "\n",
    "            for idx in range(1, len(predictions_row) + 1):  # +1 to handle the last chunk\n",
    "                if idx == len(predictions_row) or predictions_row[idx] != current_chunk_value:\n",
    "                    # Chunk ends here\n",
    "                    chunk_end = idx\n",
    "                    chunk_labels = isolated_labels_row[current_chunk_start:chunk_end]\n",
    "                    \n",
    "                    # Predicted peaks for this chunk\n",
    "                    predicted_peaks = current_chunk_value\n",
    "                    # Actual peaks for this chunk\n",
    "                    actual_peaks = int(chunk_labels.sum())  # Count the 1s in the chunk\n",
    "                    \n",
    "                    # Add squared error to total_error\n",
    "                    current_error += (predicted_peaks - actual_peaks) ** 2\n",
    "                    \n",
    "                    # Start a new chunk\n",
    "                    current_chunk_value = predictions_row[idx] if idx < len(predictions_row) else None\n",
    "                    current_chunk_start = idx\n",
    "        \n",
    "        current_error = current_error / M\n",
    "        if verbose:\n",
    "            print(f\"Peak counting error for threshold {thresh}: {current_error}\")\n",
    "        # Update the best threshold if this one performs better\n",
    "        if current_error < best_error:\n",
    "            best_error = current_error\n",
    "            best_thresh = thresh\n",
    "    if verbose:\n",
    "        print(f\"Best threshold: {best_thresh}, Best Peak Counting Error: {best_error}\")\n",
    "    return best_error, best_thresh\n",
    "\n",
    "\n",
    "# Calculate Peak Counting Error for all hyperparameter combos\n",
    "epochs = 25\n",
    "min_epoch = 24\n",
    "threshold_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "lr = 0.001\n",
    "\n",
    "for include_LSTM in [False, True]:\n",
    "    for k in [0, 3]:\n",
    "        for peak_encourage in [15, 5, 10, 1]:\n",
    "            start_time = time.time()\n",
    "            all_epoch_best_thresh = 0\n",
    "            all_epoch_best_error = np.inf\n",
    "            best_epoch = 0\n",
    "\n",
    "            # Preload all models for the current hyperparameter combination\n",
    "            models = {\n",
    "                i: load_model(\n",
    "                    os.path.join(\"PP Models (All Epochs)\", f\"V1_k-{k}_PE-{peak_encourage}_LSTM-{include_LSTM}_Epochs-{epochs}_LR-{lr} - epoch {i:02}.keras\"),\n",
    "                    custom_objects={\"custom_loss\": custom_loss}\n",
    "                )\n",
    "                for i in range(min_epoch, epochs + 1)\n",
    "            }\n",
    "\n",
    "            for i in range(min_epoch, epochs + 1):  # Use epochs instead of hardcoding 25\n",
    "                model_version = f\"V1_k-{k}_PE-{peak_encourage}_LSTM-{include_LSTM}_Epochs-{epochs}_LR-{lr} - epoch {i:02}\"\n",
    "                model = models[i]  # Use preloaded model\n",
    "                val_pred = model.predict(X_val, verbose=0)  # Predicted probabilities\n",
    "                best_error, best_thresh = peak_counting_error(isolated_peaks_val, val_pred, threshold_list=threshold_list)\n",
    "\n",
    "                if best_error < all_epoch_best_error:\n",
    "                    all_epoch_best_error = best_error\n",
    "                    all_epoch_best_thresh = best_thresh\n",
    "                    best_epoch = i\n",
    "\n",
    "            # Load the best model using the preloaded dictionary\n",
    "            best_model = models[best_epoch]\n",
    "            test_pred = best_model.predict(X_test, verbose=0)  # Predicted probabilities\n",
    "            test_error, test_thresh = peak_counting_error(isolated_peaks_test, test_pred, threshold_list=[all_epoch_best_thresh])\n",
    "            assert test_thresh == all_epoch_best_thresh\n",
    "            print(f\"LSTM = {include_LSTM}, k = {k}, PE = {peak_encourage}, Best Val Threshold: {round(all_epoch_best_thresh, 2)}, Best Epoch: {best_epoch}, Test Error: {round(test_error, 5)}\")\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"Execution time per model: {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKING PEAK LABELS FOR ERRORS\n",
    "\n",
    "sample_idx = 0\n",
    "spectrum = X_train[sample_idx, :]\n",
    "peak_labels = y_train[sample_idx, :, 0]\n",
    "\n",
    "# Frequency axis for the spectrum\n",
    "f = rfftfreq(32768, 1/44100)[0:8192]\n",
    "\n",
    "# Find indices where there are peaks (1 in predicted_peaks)\n",
    "peak_indices = np.where(peak_labels==1)[0]\n",
    "\n",
    "# Plot the spectrum\n",
    "plt.plot(f, spectrum, label='Original Spectrum')\n",
    "\n",
    "# Plot the peaks as scatter points\n",
    "plt.scatter(f[peak_indices], spectrum[peak_indices], color='red', label='Labeled Peaks')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Custom Loss\n",
    "# Example data: batch_size=4, N=5, nodes=3\n",
    "y_true = np.array([\n",
    "    [[0, 0.5, 0.7], [0, 0.2, -1], [0, 10000, -1000], [0, 0.3, 10], [0, 0.1, 10]],  # Sample 1\n",
    "    [[0, 0.6, 0.3], [1, 0.1, -1], [1, 0.3, 10], [0, 0.4, 10], [0, 0.7, 10]],  # Sample 2\n",
    "    [[0, 0.4, 1.5], [1, 0.8, -1], [1, 0.6, 10], [1, 0.2, 10], [0, 0.9, 10]],  # Sample 3\n",
    "    [[0, 0.5, 0.6], [0, 0.3, -1], [0, 0.7, 10], [1, 0.1, 10], [0, 0.8, 10]],  # Sample 4\n",
    "])\n",
    "\n",
    "y_pred = np.array([\n",
    "    [[0.9, 0.6, 0.8], [0.9, 0.3, 0.5], [0.5, 100000, 1000], [0.7, 0.4, 0.6], [0.2, 0.1, 0.3]],  # Sample 1\n",
    "    [[0.7, 0.5, 0.4], [0.9, 0.2, 0.3], [0.9, 0.4, 0.6], [0.6, 0.7, 0.9], [0.8, 0.7, 0.8]],  # Sample 2\n",
    "    [[0.8, 0.4, 0.5], [0.9, 0.6, 0.8], [0.9, 0.7, 0.5], [0.9, 0.3, 0.6], [0.2, 0.9, 0.7]],  # Sample 3\n",
    "    [[0.9, 0.4, 0.3], [0.9, 0.6, 0.8], [0.6, 0.9, 0.7], [0.9, 0.3, 0.5], [0.8, 0.7, 0.6]],  # Sample 4\n",
    "])\n",
    "\n",
    "# Convert to tensors\n",
    "y_true_tensor = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
    "y_pred_tensor = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
    "\n",
    "loss_value = custom_loss(y_true_tensor, y_pred_tensor)\n",
    "print(\"Loss Value:\", loss_value.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAy90lEQVR4nO3df5AU9Z3/8df+YHeBwJiFuLiyLhh/HJFIjuVEUOSiFh4metalCgQPzA+vspczCEQroPc9T7/6XUzlPIOR3eSApK5KC3Lnj7ISzripsoC4GMOvCwaiXsDdRXcloM5iIgvsfr5/7PXY09s90z07Mzvz2eejagt2tn98pnu6+9XvT3dPiTHGCAAAoMiVDncDAAAAsoFQAwAArECoAQAAViDUAAAAKxBqAACAFQg1AADACoQaAABgBUINAACwQvlwNyCM/v5+vfPOOxo3bpxKSkqGuzkAACAEY4xOnjyp2tpalZbmvo5SFKHmnXfeUV1d3XA3AwAAZKCzs1OTJ0/O+XyKItSMGzdO0sBCGT9+/DC3BgAAhNHT06O6urrEcTzXiiLUOF1O48ePJ9QAAFBk8nXpCBcKAwAAKxBqAACAFQg1AADACoQaAABgBUINAACwAqEGAABYgVADAACsQKgBAABWINQAAAArRA41O3bs0E033aTa2lqVlJToueeeSzvO9u3b1dDQoKqqKl144YVqaWnJpK0AAACBIoeaP/7xj5oxY4a+//3vhxr+yJEjuvHGGzVv3jzt27dP9957r1asWKGnn346cmMBAACCRP7up4ULF2rhwoWhh29padEFF1ygxx57TJI0bdo07d69W9/97nf1pS99KersAQAAfOX8mppdu3ZpwYIFSa/dcMMN2r17t86cOeM7Tm9vr3p6epJ+AAAAUsl5qOnu7lZNTU3SazU1NTp79qyOHz/uO05TU5NisVjip66uLtfNBAAARS4vdz95v3LcGOP7umPt2rWKx+OJn87Ozpy3EQAAFLfI19RENWnSJHV3dye9duzYMZWXl2vChAm+41RWVqqysjLXTQMAABbJeaVmzpw5am1tTXrtxRdf1KxZszRq1Khczx4AAIwQkUPNhx9+qP3792v//v2SBm7Z3r9/vzo6OiQNdB0tX748MXxjY6Pa29u1evVqHTp0SJs3b9amTZt09913Z+cdAAAAKIPup927d+vzn/984vfVq1dLkm6//Xb9+Mc/VldXVyLgSNLUqVO1bds2rVq1Sk888YRqa2u1fv16bucGAABZVWKcq3YLWE9Pj2KxmOLxuMaPHz/czQEAACHk+/jNdz8BAAArEGoAAIAVCDUAAMAKhBoAAGAFQg0AALACoQYAAFiBUAMAAKxAqAEAAFYg1AAAACsQagAAgBUINQAAwAqEGgAAYAVCDQAAsAKhBgAAWIFQAwAArECoAQAAViDUAAAAKxBqAACAFQg1AADACoQaAABgBUINAACwAqEGAABYgVADAACsQKgBAABWINQAAAArEGoAAIAVCDUAAMAKhBoAAGAFQg0AALACoQYAAFiBUAMAAKxAqAEAAFYg1AAAACsQagAAgBUINQAAwAqEGgAAYAVCDQAAsAKhBgAAWIFQAwAArECoAQAAViDUAAAAKxBqAACAFQg1AADACoQaAABgBUINAACwAqEGAABYgVADAACsQKgBAABWINQAAAArEGoAAIAVCDUAAMAKhBoAAGAFQg0AALACoQYAAFiBUAMAAKxAqAEAAFYg1AAAACtkFGo2bNigqVOnqqqqSg0NDdq5c2fK4Z988knNmDFDY8aM0XnnnaevfOUrOnHiREYNBgAA8BM51GzdulUrV67Ufffdp3379mnevHlauHChOjo6fIf/5S9/qeXLl+trX/uafvvb3+o//uM/9Otf/1p33HHHkBsPAADgiBxqHn30UX3ta1/THXfcoWnTpumxxx5TXV2dmpubfYd/5ZVXNGXKFK1YsUJTp07V1Vdfra9//evavXv3kBsPAADgiBRqTp8+rT179mjBggVJry9YsEBtbW2+48ydO1dHjx7Vtm3bZIzRu+++q//8z//UF77whcD59Pb2qqenJ+kHAAAglUih5vjx4+rr61NNTU3S6zU1Neru7vYdZ+7cuXryySe1ePFiVVRUaNKkSTrnnHP0+OOPB86nqalJsVgs8VNXVxelmQAAYATK6ELhkpKSpN+NMYNecxw8eFArVqzQP/3TP2nPnj164YUXdOTIETU2NgZOf+3atYrH44mfzs7OTJoJAABGkPIoA0+cOFFlZWWDqjLHjh0bVL1xNDU16aqrrtI999wjSbr88ss1duxYzZs3Tw899JDOO++8QeNUVlaqsrIyStMAAMAIF6lSU1FRoYaGBrW2tia93traqrlz5/qO86c//UmlpcmzKSsrkzRQ4QEAAMiGyN1Pq1ev1saNG7V582YdOnRIq1atUkdHR6I7ae3atVq+fHli+JtuuknPPPOMmpubdfjwYb388stasWKFrrjiCtXW1mbvnQAAgBEtUveTJC1evFgnTpzQgw8+qK6uLk2fPl3btm1TfX29JKmrqyvpmTVf/vKXdfLkSX3/+9/Xt771LZ1zzjm69tpr9cgjj2TvXQAAgBGvxBRBH1BPT49isZji8bjGjx8/3M0BAAAh5Pv4zXc/AQAAKxBqAACAFQg1AADACoQaAABgBUINAACwAqEGAABYgVADAACsQKgBAABWINQAAAArEGoAAIAVCDUAAMAKhBoAAGAFQg0AALACoQYAAFiBUAMAAKxAqAEAAFYg1AAAACsQagAAgBUINQAAwAqEGgAAYAVCDQAAsAKhBgAAWIFQAwAArECoAQAAViDUAAAAKxBqAACAFQg1AADACoQaAABgBUINAACwAqEGAABYgVADAACsQKgBAABWINQAAAArEGoAAIAVCDUAAMAKhBoAAGAFQg0AALACoQYAAFiBUAMAAKxAqAEAAFYg1AAAACsQagAAgBUINQAAwAqEGgAAYAVCDQAAsAKhBgAAWIFQAwAArECoAQAAViDUAAAAKxBqAACAFQg1AADACoQaAABgBUINAACwAqEGAABYgVADAACsQKgBAABWyCjUbNiwQVOnTlVVVZUaGhq0c+fOlMP39vbqvvvuU319vSorK/XpT39amzdvzqjBAAAAfsqjjrB161atXLlSGzZs0FVXXaUf/OAHWrhwoQ4ePKgLLrjAd5xFixbp3Xff1aZNm3TRRRfp2LFjOnv27JAbDwAA4CgxxpgoI8yePVszZ85Uc3Nz4rVp06bplltuUVNT06DhX3jhBd166606fPiwqqurM2pkT0+PYrGY4vG4xo8fn9E0AABAfuX7+B2p++n06dPas2ePFixYkPT6ggUL1NbW5jvO888/r1mzZuk73/mOzj//fF1yySW6++679dFHHwXOp7e3Vz09PUk/AAAAqUTqfjp+/Lj6+vpUU1OT9HpNTY26u7t9xzl8+LB++ctfqqqqSs8++6yOHz+ub3zjG3rvvfcCr6tpamrSAw88EKVpAABghMvoQuGSkpKk340xg15z9Pf3q6SkRE8++aSuuOIK3XjjjXr00Uf14x//OLBas3btWsXj8cRPZ2dnJs0EAAAjSKRKzcSJE1VWVjaoKnPs2LFB1RvHeeedp/PPP1+xWCzx2rRp02SM0dGjR3XxxRcPGqeyslKVlZVRmgYAAEa4SJWaiooKNTQ0qLW1Nen11tZWzZ0713ecq666Su+8844+/PDDxGtvvPGGSktLNXny5AyaDAAAMFjk7qfVq1dr48aN2rx5sw4dOqRVq1apo6NDjY2Nkga6jpYvX54YfunSpZowYYK+8pWv6ODBg9qxY4fuueceffWrX9Xo0aOz904AAMCIFvk5NYsXL9aJEyf04IMPqqurS9OnT9e2bdtUX18vSerq6lJHR0di+E984hNqbW3VN7/5Tc2aNUsTJkzQokWL9NBDD2XvXQAAgBEv8nNqhgPPqQEAoPgU9HNqAAAAChWhBgAAWIFQAwAArECoAQAAViDUAAAAKxBqAACAFQg1AADACoQaAABgBUINAACwAqEGAABYgVADAACsQKgBAABWINQAAAArEGoAAIAVCDUAAMAKhBoAAGAFQg0AALACoQYAAFiBUAMAAKxAqAEAAFYg1AAAACsQagAAgBUINQAAwAqEGgAAYAVCDQAAsAKhBgAAWIFQAwAArECoAQAAViDUAAAAKxBqAACAFQg1AADACoQaAABgBUINAACwAqEGAABYgVADAACsQKgBAABWINQAAAArEGoAAIAVCDUAAMAKhBoAAGAFQg0AALACoQYAAFiBUAMAAKxAqAEAAFYg1AAAACsQagAAgBUINQAAwAqEGgAAYAVCDQAAsAKhBgAAWIFQAwAArECoAQAAViDUAAAAKxBqAACAFQg1AADACoQaAABghYxCzYYNGzR16lRVVVWpoaFBO3fuDDXeyy+/rPLycn3uc5/LZLYAAACBIoearVu3auXKlbrvvvu0b98+zZs3TwsXLlRHR0fK8eLxuJYvX67rrrsu48YCAAAEKTHGmCgjzJ49WzNnzlRzc3PitWnTpumWW25RU1NT4Hi33nqrLr74YpWVlem5557T/v37Q8+zp6dHsVhM8Xhc48ePj9JcAAAwTPJ9/I5UqTl9+rT27NmjBQsWJL2+YMECtbW1BY73ox/9SL///e91//33h5pPb2+venp6kn4AAABSiRRqjh8/rr6+PtXU1CS9XlNTo+7ubt9x3nzzTa1Zs0ZPPvmkysvLQ82nqalJsVgs8VNXVxelmQAAYATK6ELhkpKSpN+NMYNek6S+vj4tXbpUDzzwgC655JLQ01+7dq3i8Xjip7OzM5NmAgCAESRc6eR/TZw4UWVlZYOqMseOHRtUvZGkkydPavfu3dq3b5/uvPNOSVJ/f7+MMSovL9eLL76oa6+9dtB4lZWVqqysjNI0AAAwwkWq1FRUVKihoUGtra1Jr7e2tmru3LmDhh8/frwOHDig/fv3J34aGxt16aWXav/+/Zo9e/bQWg8AAPC/IlVqJGn16tVatmyZZs2apTlz5uiHP/yhOjo61NjYKGmg6+jtt9/Wv//7v6u0tFTTp09PGv/cc89VVVXVoNcBAACGInKoWbx4sU6cOKEHH3xQXV1dmj59urZt26b6+npJUldXV9pn1gAAAGRb5OfUDAeeUwMAQPEp6OfUAAAAFCpCDQAAsAKhBgAAWIFQAwAArECoAQAAViDUAAAAKxBqAACAFQg1AADACoQaAABgBUINAACwAqEGAABYgVADAACsQKgBAABWINQAAAArEGoAAIAVCDUAAMAKhBoAAGAFQg0AALACoQYAAFiBUAMAAKxAqAEAAFYg1CArdixt0dHyKdqxtGW4mwIAGKEINciKC3+yTpP72nXhT9YNd1MAACMUoQZZcXjRGh0tq9fhRWuGuykAgBGqxBhjhrsR6fT09CgWiykej2v8+PHD3RwAABBCvo/fVGoAAIAVCDUAAMAKhBoAAGAFQg0AALACoQYAAFiBUAMAAKxAqEFWtLRIU6YM/AsAwHAg1CAr1q2T2tsH/gUAYDgQapAVa9ZI9fUD/wIAMBwINRiylpaBCs2aNVJj43C3BgAwUhFqMGR0PQEACgGhBkNG1xMAoBDwhZYAACAn+EJLAACADBBqAACAFQg1AADACoQaAABgBUINhsT99Qh8VQIAYDhx9xOGZMqUgWfU1NcP/O78/623hrNVAIBCwN1PKCruZ9TwvBoAwHCiUgMAGdqxtEUX/mSdDi9ao2ue4jtCAC8qNQBQJC78yTpN7mvXhT/hO0KAQkCoAYAAO5a26Gj5FO1Y2qIdS1v0XukEvVc6QTuWDlwNf3jRGh0tq9fhRfS5AoWA7icACHC0fIom97XraNnAlfCT+9oHXi+r1+Szbw0aPlV3FN9mj5GI7icAKBDt58/VWZUpXvkpjek/qT9qjN4rqVa88lM6W1Kul+uXJlVzUnVH8W32QO4RagCMOOmeqeQElWmdP1e5+nTpn/ap2ryn98s+per+E7r0T/tUrj7N7vhJUpBxuqPaz5+bCDoO7g4Eco9QA2BEcAcZp2py333+4Wb6lvs0ua9dleaUjpbV6/Uxf66zKlP7+XMlSb+6YJHOqky/umCRDi9ao/dKqjWm/6QkafLZt1T/dtugik1j40CgWbeOB1QCuUKoATAiuLt/nKqJlNwl5AQf50rDKp3S4UVrFOv9g8rVp/q32yRJV7U/pXJzVn1XXZMILtXmvcT/nYrNz/98TVJocreBJ3AD2UeowZCwY0axcHf/NDYOPPX64YeTu4Sc0PH/xjyssypTmfoHdSu574Byup4qzCn1qUSf7PuDdixt0TVPNWry2bf0f//QmBSanDbMnSvdeSfX2ADZRqjBkHDxIwqRN2z73XnU0jLQ/XTy5MfjrVkjrR7TortOrdOvLliUuF3bCSn1b7ep2ryXqMo4Yed0SZXKZDRWf0pUa3YsbdGe9gk6rgn6P58aaIgTptrapL4+qaxsIOBwYgBkiSkC8XjcSDLxeHy4mwKP5mZj6usH/gUKQXOzMWVlxkgDn01jBv51/+5+TTKmuvrjz3Fn2cAfOssGBt6+pNl0ltWb7UuazfYlzeZESbU5UVJtti/5+EPvvP6hxpgPNSYxjDMDZ1ruNjrzc9rhbgNgi3wfvzMKNU888YSZMmWKqaysNDNnzjQ7duwIHPbpp582119/vZk4caIZN26cufLKK80LL7wQaX6EmuJByMFwc0JCWdnHn8MlSwZ+X7Lk4+GamweChPPjhB53iDFmcMhJxRnWSOasShIBZ+Os5sR24d1GnN/dbQBsUfChZsuWLWbUqFHm3/7t38zBgwfNXXfdZcaOHWva29t9h7/rrrvMI488Yl599VXzxhtvmLVr15pRo0aZvXv3hp4noaZ4+J0RA/nkhIQlS/xDi9/wY8YYU1Iy8K83kHtDTqrXnYrNWZUmBSH3dhG0jXBCABsVfKi54oorTGNjY9Jrf/Znf2bWrFkTehqf+cxnzAMPPBB6eEJN8WDHjHxK9XkL6l7yjuMeLkogT1XBcQceJzSVlg4ErWxsI2xnKBYFHWp6e3tNWVmZeeaZZ5JeX7FihbnmmmtCTaOvr8/U1dWZxx9/PHCYU6dOmXg8nvjp7Owk1ACWy+RA7a16uKfhDROpxqmuHhi2ujr8/IMqOEFt9AYmd/dXqnm6K0/e63CoiKLQFXSoefvtt40k8/LLLye9/vDDD5tLLrkk1DS+853vmOrqavPuu+8GDnP//fcbSYN+CDWFgzNFDIXf5yfKgdp7oHf+HTPm48qM3zQzDTBDERRe3GHHff2Pl/saIee9eMMb2yIKVVGEmra2tqTXH3roIXPppZemHf+pp54yY8aMMa2trSmHo1JT+DhTxFD4fX6iHJy94zu/l5Qkh5qgribv3VGZtGGonLBTWvpxm9zVGG+b/P5mTOpqFTDcCjrUDKX7acuWLWb06NHmpz/9aeRGck1N4WHHCT9hPxdRPz9Bdwx5726aNSv1dKMGhHxw34KeSdjyvifuokIhKehQY8zAhcJ///d/n/TatGnTUl4o/NRTT5mqqirz7LPPRm6gMYSaQkWwgVe2QkGYA3XQLdnZmG++P9Pu9+t3UXGY9+d+3o1fdxfbK4ZDwYca55buTZs2mYMHD5qVK1easWPHmrfeessYY8yaNWvMsmXLEsM/9dRTpry83DzxxBOmq6sr8fPBBx+EniehpjDl8qyWHXBxSldRCcvbTeR395JzoPc7kAfNtxA+V+na4K7auLvVqquDK0ze6aZ62CAVHORTwYcaYwYevldfX28qKirMzJkzzfbt2xN/u/322838+fMTv8+fP9/3ot/bb7899PwINYUplwcIdsB2CLse03UnOc+ccaoYfkEm6Fkw6Q72+ZauDe4HBXqfjpzp8gx6Dci1ogg1+VYsoYadxseGuixYlsUh3XoKe3D1hpCgrznwu1vI7zqZoCBTCJ+rMG0IurupENoPREGo8VEsoaYQzgKjyvZOMso1ACh+mXzm3V1Ls2YNvsDX/Xd3hcb5Cbo1OqgNxRIEolaUiuV9YWQj1PjI9kLJ1c6gGHcymRyUUr1P7zUAxbQscqEYPxNRZPL+3JUYd+XF+Ztfl5INoSUdb0Up6MF8UU8cbFk+KE6EGh/ZXijFWFHJlUx2eKmWn1/XwUhm+2fNr2sk1cWs3vGcSo3zxF/v8kp1cLeNd1t0QovzzB2H+y6nMNuu7Z9BFDZCjY9iqdRkQyG3zZHJdRQjVaEsi1R3JUVpo3dYv4tzw4Zav/l6L5IthGU3XLyhJkxoTBcyR/oyRf4Ranw4C+XRR6MvlChnj7kUdmcS9SysGBTKOhgp0l2I6/3drzqSrnvRO6z7G7HDrme/CkKqdo00qQKk3zBBd0q5L6pOV2Vl+0S2EWp8OAulri7aQnFv5H7Pu8insBcz2vhU0Khn8PAXNRj7Hfy835Xkd3dNqqfaBgWXbF2bla6CNJIPvH4nB+5ty9lnOCFmyZLB1yOl6s6z8YQKw49Q4yPTSo2zkTtP5/QLC6nK8tmUbrreg4K7DJ+teQyHVAdC73CZtD2b4xXi8nMLGxzCVFqCDlx+Z/d+849S3QnbtjBGevXGmORl4A6h3gf0uUNOqm/4ztUJVaFvT8gPQo0P70IJu7H4XWiXbgMeyk7Te5YZ5QLHMKXmdLK5w8/WDinswS/Ttqcrp0epLOT7gBl1GYcZPuz1TkHh3rucgionmbZ9qAdMujL9T8T8up3cwdUbhFJtC7na9jEyEWp8eBdKLs9Yg8YJs6H7ncmG3aijVoxyXWnwLh+/boswgnagYR9rn+59hVnHfl1ffpWwXFXtMglymc47020jaLyoByZnut67mpwwk61b/TlgJgvTbZfuFvF8V6cxMhBqfDgLZfTouCktHfxNvGEP8FHPNN1nhe6Dot903BdKZlKpibqTzvZO3e+AXl09cBByP0/E+d17m2nU+bi/tyfde8j0vQZVarxntn7t8yvTu/8eJdx5z5LDdMcFvedMwm6Ydmc6XlC7vc+fibK+w+CAGZ53m+OaGeQTocaHs1CkeNKO0hG2KyHouQ9e3p2A+2Jj78HO+b/fQTLKASHqwSOTa26883LPI9UydB+gxowZ+P+YMUOr2EQJfWHCaJSDnHudBXVLBX3Tcar1HdQOv6CU7uCeSXUn7HsOc8F6mPmmeq/eSo2zvv2eCJxqvggWdpl5q66ZPLSvGNdP1BNL5Aahxoe3UuPeUbp3oO4Kjt9GGPa5D85OwO+bcb0bSqow4g0FYQ5EYQ9aQ6nUhK1AuA9EzsEo7MWEYbs30o0X1Hbv2WbQ66nm4a3Auf8W9P7Shc907zPo8xM2xHqrlGGFrdSke9/pgnDQfNN9DrJdeRwJMt2mooYh78nbUANCvgJS2BMI5BahxoffQnF3IXj/jXqg9TuwBU0r6sHTW+VJ1ya/s4t0Z/+p5u8NeX7PE0l1Z4T3fTvvI2r4CHvnk3f+QTvkoAtdo1yImmpHnemOd8mSgTA8Zky0qpFfe91t8H6OMglGYdrhF+SDhJlvmM8NZ9SZGcp696ucpQo/qfaJUeUrwPK5KgyEGh9+t3S7d5ZDvYjVb7ygHYb34JnugBi0o0hV8XBv9N4DWtDdKX7PHXFP2y/A+VWSgrq1ou7UooQM7/v125F6Q6Q3PPjtpMO2MVUwCHvg8L5fb5uDPmuppu9eLu714l5vzjwyPYsOqlqF7aoNM/10nxuqNPnn3farqzPvmgz793TDpasmojgRanz4PXxvuFO4e2c9Zkzq769xj+NcaOv863dtil/lwn1di3va3rDi3jmlO6j6BaZUlaVMzgyjVpTc3O/NuZbHOch6S8tDLTWnq1Clq8y5h3PCVWlp+muvvMEqTAWmufnjaTvDep9VEnS27Q1UQRfAu0NNqjP4MLJ1MET2uPdFpaWpT9LCSrXfC3PCELSNoLgRanwEPXwv7Ble2I0q6tm087pzgHF/03Cqg7Q71IS9aNnpNho1yvheV+T3wK0wQcKv6ymX/dBRKiJBB1nnb6nuNsv0wOtd907Qc0JV2LNYZ1l6u3NSXb/lfI6ifKbd03V/87U39LqDlfeC0XQB1rudUVmxQ5hKZabTc7+WrivfG/Ddn+lsnbgSnIcPocZH0MP3woaPdGfhQVWPoJ24d/7eOz2CuA+8Ubq8vO1N1e2WLhw4wjyYMBc7gEwrIlF3SpkG3qADv1/VK6gCZkz6MOQezx1Goj7Hxf0+/aqXfm2NemtvppUaDiTFZyiVVT9B4T5MkBpq9dVvWoUWxEfCNkKo8RH24XtDLX967zDxhgYnvDgHqii39YaRbsNzDlruylBQO/zOtN1n5EF3guV640oXSKPeVZVuPumGCwqs3gN/0MXUznDurib3dIPCkDeMON1VUW/Rz2S9ZWMcb1hKdft7oR1IkCxVVc5vuCgX43vH8bveLNW47s9VmMdYRKkEF4KRsI0Qany4F0rQDtSYoVca0pXZ3dctpJpPph/UqAdsvzKt3wXIfiXgoApFrjausPMLe/YW9D6itiNs1c8dDN3LO+i5PX7t8gaZoS6PbOyo003f/byedN1aqYI1Cleqz6XfcN6gH6ZS3dz8cfB3X8MTZX/j3f+mamOxhISRsI0Qany4F0qYg1rUD3bYA1vYB96l+6Dm4oPsPuj67XjS9U/neuMaahhxhAkDfsEl6OAc1D6/+frdOebcgRWmyyhMQPF+BlPdheRXgYsyT/c0/N63O6x4z6zDVGpQHMLur4KuB3N3iaeanvfi86ifGW+XbjYfxWCjQlkWhBof3kpNqoOa38YylB17NuSyKuJXtQma13CexYQpCwf9P8p0/apS7p2v9061dO1L1VZv91/Ya1RSzc+7jtzdW37LKNWdIun+nu59E1ZGNuez4a36uqvC7uvBwtz9GVT9jLrNp+tyL0T5bl++9vfp3hehxkeqhZJuQ3G/FlQlKOQqxVAD2XCeUYd5n0GhK8oG6Z6Pu4LivTPKe5v1UHkDZSYP/gva8fvd1eS3XMJ0F2TjKbDe9hXqgQPZ4z4ZcK73cr/m3ubcn4egyo6XO5yEeU6Od1zvtLN9EM/0xCpI0PYY9YQq7N/yta2mW+6EGh9RFopfis9lpSSMoXy4ooSWbEwvm8LMK0qlJkx1w+/s0jtcNg/yQe9lqMP6vadUZ7N+QT3VnXaZGs5qH/LDHUq8jwlwnyB4T44y2c96t1f3thk2HAXNf6gH9bCf9bDDBVWYwoyfaphMtslMlk2m4YlQ4yPqQkm3kIvlbDMXB6Z8vvdszytsWTvKa2Hk+/OSSUXNu2wyrXqFaVsxbDvInDdQh72zLdsVafdJSCbXSAZVTrNdgRnq+wxThUl1K3wmx7so+4RUwTMMQo2PMAvFxp1trg5MYeRyeWa6E8hVm9LtJPK97LNx5pWP5QY7Zdodku3PWZgDuh9n+wm6xi3q9pWv7Sds+Aiq4gbxm0aUIORenlEeY+K89ud/TqgZJEyoGeqBJ1sf3KjTCZPSh+PAlMsDebpp+21QuQwUqaoc3vbkAyEENsnm5zlKl1a6A3bY6ndQiEh3MhS14uq33/Eb3+974FItD+9du1GDUJgeg1ThSyLUDJKPSk22Dp5Rp+MusRbSQWw4KzVRz0SGMi+/YQgVQGYy6eqIUjUIExTCbr9h99VBJ1nexy0EnRxlevFzUPvclZMwyyLdE/L9xvFON5N1SKUmhXz0yQ1Hpcb58GTzjhwb5PvMDkB2ZNLVke4kJigshO1eCpp/1IqNd1reUONXEcnkbtN07XL+HuaaIb+TZud170MTU003TI9CUHu5psZHvhdKvqTbOLOh0KsOmbQvanAs5PcPFKJMu9EzuaEhXXdzUCU11UHdHSbSndhkuh9OVVkJU30KCjyZVJCCxk/VDvdzttzjeZ/l5bdug4KTX7sJNT6GM9QMZzdMNqadyePI8ymTSkoxVl8IVygmmXajD3WbjBKOUj3hPWrAiLKvDApZQd8P5zdOqq6poXaHhx3evfzcISvoK1GCnpdFpSYDwxlqivEAakx+qkDZkOtKTbZlOu9i/RxhZBrKgTQbB+Ew24t3HxfmLqlU7cw0/KTq4gm6JiVVpSbduGHaGpX7PQR9XVDUu9CcYR59lFAziK2Vmlwq1nYXukzDCesDI0W6bWQoB3y/6bifnxL2GhN3tcEbRtJ1C7krGs536rmvi/Tb1qNs/97l4VRUZs1K3U0XVlD7/B5am+kT6N3TKy0l1Axi6zU1KD6EEyC1dNtI2K6ZsAfsdN0f3jDiPA3Z+xUk7mH9qtx+t1L7fe9buveXbjkFLQ93W9NVmTK5ZidKF5nfOH7hkVu6AxBqAMAOYbt5Mq10BE3P+XbvVFWV5uaPvyPOGd4beNJdRxI2pIUNb+lCm1/bvF9vEXY6bkuWDHyH3pgx/sN6qztBy6eujlAzCKEGAIpHrq75CNul5cfpphozJlwlyVupyfQ9Ra3UZMKvSuL+Ul9jolfA0g3vLM/S0uRKjTc0caGwD0INABSPoVzz4Sdql1Ym04g6XDpDDTNRL2TOdL6ZttP7nB6Hd10QanwQagCgeOTz2rOhXNAadvqZhIuhdjt5hxtqUAxqd7avYfLOh1Djg1ADRMMFzci1QvmMZaMqFBRcUl1M7Dc/vwtng26RznalJtNqVtT1GPb9Owg1Pgg1QDTZLv8DXoXwGctWlSaoKuJ+6m6YcOG3THK1nFLdJRV0YW8uu9XcbXC/V0KND0INEE2hnEXDXoXwGcs0MHgrKt5gFPVOIfd0g6aV7Wt5vO/dezdS2PZmcx36vX9CjQ9CDQDAK9ODsjsQZPMiY++0M21TmHb4tSmbXUmZGu4LhUsFAEARamyU3npr4N8o1qyR6usH/nX+P3euNGWK1NIyePh166T29oF/o0w7apuqq6WTJ/3b4G2H896lj9sddXlk2tZ8TzOKEmOMGZ5Zh9fT06NYLKZ4PK7x48cPd3MAAJaZMmUgMNTXfxwWHC0tA0FizZroASpbbQhqhzNOdbU0blzu2xhVvo/fVGoAACNeqgpDphUhPy0twRWhdFUOv3Y440jhq0k2o1IDAECOOVWWkyel994LrsYMdfqpKjX5qji55fv4TagBACDHCqGbKF33Vi7Q/QQAgGWcbqKHH07uQkrVHZUtzjzmzh3ei3jzgUoNAADDJB/Vk7DzyEX3FJUaAABGiHzcAh12HlFuXS9UVGoAABih3NUZqfgrNYQaAABGqFx3f9H9BADACJaPi4cdw/0E4GyjUgMAwDDyXqA7HLde5wqVGgAARhDvBbq2VU/yiVADAMAw8oaYbH4tw0hD9xMAAMiJouh+2rBhg6ZOnaqqqio1NDRo586dKYffvn27GhoaVFVVpQsvvFAt+bj6CQAAjCiRQ83WrVu1cuVK3Xfffdq3b5/mzZunhQsXqqOjw3f4I0eO6MYbb9S8efO0b98+3XvvvVqxYoWefvrpITceAADAEbn7afbs2Zo5c6aam5sTr02bNk233HKLmpqaBg3/7W9/W88//7wOHTqUeK2xsVH//d//rV27doWaJ91PAAAUn4Lufjp9+rT27NmjBQsWJL2+YMECtbW1+Y6za9euQcPfcMMN2r17t86cOeM7Tm9vr3p6epJ+AADA8MrnM3QyESnUHD9+XH19faqpqUl6vaamRt3d3b7jdHd3+w5/9uxZHT9+3HecpqYmxWKxxE9dXV2UZgIAgBwo9O+HyuhC4ZKSkqTfjTGDXks3vN/rjrVr1yoejyd+Ojs7M2kmAADIokJ/hk55lIEnTpyosrKyQVWZY8eODarGOCZNmuQ7fHl5uSZMmOA7TmVlpSorK6M0DQAA5FhjY2E/PydSpaaiokINDQ1qbW1Ner21tVVz5871HWfOnDmDhn/xxRc1a9YsjRo1KmJzAQAA/EXuflq9erU2btyozZs369ChQ1q1apU6OjrU+L/Rbe3atVq+fHli+MbGRrW3t2v16tU6dOiQNm/erE2bNunuu+/O3rsAAAAjXqTuJ0lavHixTpw4oQcffFBdXV2aPn26tm3bpvr6eklSV1dX0jNrpk6dqm3btmnVqlV64oknVFtbq/Xr1+tLX/pS9t4FAAAY8fiaBAAAkBMF/ZwaAACAQkWoAQAAViDUAAAAKxBqAACAFQg1AADACoQaAABgBUINAACwAqEGAABYgVADAACsEPlrEoaD89Djnp6eYW4JAAAIyzlu5+vLC4oi1Jw4cUKSVFdXN8wtAQAAUZ04cUKxWCzn8ymKUFNdXS1J6ujoyMtCQbCenh7V1dWps7OT7+EaZqyLwsG6KCysj8IRj8d1wQUXJI7juVYUoaa0dODSn1gsxge0QIwfP551USBYF4WDdVFYWB+FwzmO53w+eZkLAABAjhFqAACAFYoi1FRWVur+++9XZWXlcDdlxGNdFA7WReFgXRQW1kfhyPe6KDH5us8KAAAgh4qiUgMAAJAOoQYAAFiBUAMAAKxAqAEAAFbIS6hpbm7W5ZdfnngQ0pw5c/Rf//Vfib8bY/TP//zPqq2t1ejRo/WXf/mX+u1vf5s0jd7eXn3zm9/UxIkTNXbsWN188806evRo0jDvv/++li1bplgsplgspmXLlumDDz7Ix1ssGqnWxZkzZ/Ttb39bn/3sZzV27FjV1tZq+fLleuedd5KmwbrInnTbhtvXv/51lZSU6LHHHkt6nfWRHWHWxaFDh3TzzTcrFotp3LhxuvLKK9XR0ZH4O+siO9Ktiw8//FB33nmnJk+erNGjR2vatGlqbm5OmgbrIjeamppUUlKilStXJl4rqGO4yYPnn3/e/OxnPzOvv/66ef311829995rRo0aZV577TVjjDHr1q0z48aNM08//bQ5cOCAWbx4sTnvvPNMT09PYhqNjY3m/PPPN62trWbv3r3m85//vJkxY4Y5e/ZsYpi/+qu/MtOnTzdtbW2mra3NTJ8+3Xzxi1/Mx1ssGqnWxQcffGCuv/56s3XrVvO73/3O7Nq1y8yePds0NDQkTYN1kT3ptg3Hs88+a2bMmGFqa2vNv/7rvyb9jfWRHenWxf/8z/+Y6upqc88995i9e/ea3//+9+anP/2peffddxPTYF1kR7p1cccdd5hPf/rT5qWXXjJHjhwxP/jBD0xZWZl57rnnEtNgXWTfq6++aqZMmWIuv/xyc9dddyVeL6RjeF5CjZ9PfvKTZuPGjaa/v99MmjTJrFu3LvG3U6dOmVgsZlpaWowxxnzwwQdm1KhRZsuWLYlh3n77bVNaWmpeeOEFY4wxBw8eNJLMK6+8khhm165dRpL53e9+l6d3VZycdeHn1VdfNZJMe3u7MYZ1kQ/e9XH06FFz/vnnm9dee83U19cnhRrWR26518XixYvN3/7t3wYOy7rILfe6uOyyy8yDDz6Y9PeZM2eaf/zHfzTGsC5y4eTJk+biiy82ra2tZv78+YlQU2jH8LxfU9PX16ctW7boj3/8o+bMmaMjR46ou7tbCxYsSAxTWVmp+fPnq62tTZK0Z88enTlzJmmY2tpaTZ8+PTHMrl27FIvFNHv27MQwV155pWKxWGIYJPOuCz/xeFwlJSU655xzJLEucslvffT392vZsmW65557dNlllw0ah/WRG9510d/fr5/97Ge65JJLdMMNN+jcc8/V7Nmz9dxzzyXGYV3kht92cfXVV+v555/X22+/LWOMXnrpJb3xxhu64YYbJLEucuEf/uEf9IUvfEHXX3990uuFdgzP2xdaHjhwQHPmzNGpU6f0iU98Qs8++6w+85nPJBpbU1OTNHxNTY3a29slSd3d3aqoqNAnP/nJQcN0d3cnhjn33HMHzffcc89NDIMBQevC69SpU1qzZo2WLl2a+FI41kX2pVofjzzyiMrLy7VixQrfcVkf2RW0Lrq7u/Xhhx9q3bp1euihh/TII4/ohRde0N/8zd/opZde0vz581kXWZZqu1i/fr3+7u/+TpMnT1Z5eblKS0u1ceNGXX311ZLYLrJty5Yt2rt3r379618P+puzrArlGJ63UHPppZdq//79+uCDD/T000/r9ttv1/bt2xN/LykpSRreGDPoNS/vMH7Dh5nOSBO0LtzB5syZM7r11lvV39+vDRs2pJ0m6yJzQevjo48+0ve+9z3t3bs38nJjfWQmaF04lcq//uu/1qpVqyRJn/vc59TW1qaWlhbNnz8/cJqsi8yk2k+tX79er7zyip5//nnV19drx44d+sY3vqHzzjtvUCXBjXURXWdnp+666y69+OKLqqqqChyuUI7heet+qqio0EUXXaRZs2apqalJM2bM0Pe+9z1NmjRJkgYlsWPHjiWS36RJk3T69Gm9//77KYd59913B833D3/4w6AEOdIFrQvHmTNntGjRIh05ckStra2JKo3EusiFoPWxc+dOHTt2TBdccIHKy8tVXl6u9vZ2fetb39KUKVMksT6yLWhdTJw4UeXl5YMqmtOmTUvc/cS6yK6gdfHRRx/p3nvv1aOPPqqbbrpJl19+ue68804tXrxY3/3udyWxLrJpz549OnbsmBoaGhL7oe3bt2v9+vUqLy9PLKtCOYYP23NqjDHq7e3V1KlTNWnSJLW2tib+dvr0aW3fvl1z586VJDU0NGjUqFFJw3R1dem1115LDDNnzhzF43G9+uqriWF+9atfKR6PJ4aBP2ddSB8HmjfffFO/+MUvNGHChKRhWRe556yPZcuW6Te/+Y3279+f+KmtrdU999yjn//855JYH7nmrIuKigr9xV/8hV5//fWkv7/xxhuqr6+XxLrINWddnDlzRmfOnFFpafLhq6ysTP39/ZJYF9l03XXX6cCBA0n7oVmzZum2227T/v37deGFFxbWMTz0JcVDsHbtWrNjxw5z5MgR85vf/Mbce++9prS01Lz44ovGmIHbwWKxmHnmmWfMgQMHzJIlS3xvB5s8ebL5xS9+Yfbu3WuuvfZa39vBLr/8crNr1y6za9cu89nPfpbb8zxSrYszZ86Ym2++2UyePNns37/fdHV1JX56e3sT02BdZE+6bcPLe/eTMayPbEm3Lp555hkzatQo88Mf/tC8+eab5vHHHzdlZWVm586diWmwLrIj3bqYP3++ueyyy8xLL71kDh8+bH70ox+Zqqoqs2HDhsQ0WBe54777yZjCOobnJdR89atfNfX19aaiosJ86lOfMtddd13STru/v9/cf//9ZtKkSaaystJcc8015sCBA0nT+Oijj8ydd95pqqurzejRo80Xv/hF09HRkTTMiRMnzG233WbGjRtnxo0bZ2677Tbz/vvv5+MtFo1U6+LIkSNGku/PSy+9lJgG6yJ70m0bXn6hhvWRHWHWxaZNm8xFF11kqqqqzIwZM5Kei2IM6yJb0q2Lrq4u8+Uvf9nU1taaqqoqc+mll5p/+Zd/Mf39/YlhWBe54w01hXQMLzHGmIzrUgAAAAWC734CAABWINQAAAArEGoAAIAVCDUAAMAKhBoAAGAFQg0AALACoQYAAFiBUAMAAKxAqAEAAFYg1AAAACsQagAAgBUINQAAwAr/H+37YLX3fbi+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a sample\n",
    "i = 1\n",
    "spectrum = X_train[i]\n",
    "f = rfftfreq(32768, 1/44100)[0:8192]\n",
    "\n",
    "labels = y_train[i, :, :]\n",
    "spread_peak_labels = labels[:, 0]\n",
    "indices = np.where(spread_peak_labels == 1)[0]\n",
    "# isolated_peaks = isolated_peaks_train[i]\n",
    "# indices = np.where(isolated_peaks == 1)[0]\n",
    "plt.scatter(f, spectrum, color='blue', s=1)\n",
    "plt.scatter(f[indices], spectrum[indices], color='red', s=1)\n",
    "plt.xlim(3000, 4000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify peak_counting_error\n",
    "isolated_peaks=np.array(\n",
    "    [[0, 1, 0, 0, 1], \n",
    "     [1, 0, 1, 0, 0]]\n",
    "    )\n",
    "predictions=np.array(\n",
    "    [[0.81, 0.91, 0.71, 0.31, 0.91],\n",
    "     [0.81, 0.21, 0.91, 0.96, 0.91]]\n",
    "    )\n",
    "\n",
    "peak_counting_error(isolated_peaks, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out how many bins our peaks are\n",
    "f = rfftfreq(32768, 1/44100)\n",
    "# HWFM (in bins) of a peak with a HWHM of 100Hz\n",
    "bin_width = f[1] - f[0]\n",
    "print(f\"HWFM (in bins) of a peak with a HWHM of 100Hz: {200 / bin_width}\")\n",
    "print(f\"HWFM (in bins) of a peak with a HWHM of 10Hz: {20 / bin_width}\")\n",
    "print(f\"HWFM (in bins) of a peak with a HWHM of 3Hz: {6 / bin_width}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
