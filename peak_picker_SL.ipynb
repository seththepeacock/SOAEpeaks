{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, Dense, Concatenate, TimeDistributed, LSTM, Bidirectional, Layer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.autograph.experimental import do_not_convert\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from helper_funcs import gen_samples\n",
    "from scipy.fft import rfftfreq\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First navigate to our directory\n",
    "transfer_directory_path = os.path.join(\"Data\", \"synth_transfer_df.parquet\")\n",
    "general_directory_path = os.path.join(\"Data\", \"synth_general_df.parquet\")\n",
    "# Load the dataframes\n",
    "synth_transfer_df = pd.read_parquet(transfer_directory_path)\n",
    "synth_general_df = pd.read_parquet(general_directory_path)\n",
    "# Concatenate (after making sure they share columns) and then reset indices\n",
    "assert list(synth_transfer_df.columns) == list(synth_general_df.columns), \"Column names do not match!\"\n",
    "df = pd.concat([synth_transfer_df, synth_general_df], axis=0)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs=1\n",
    "# Split into train (70%) and temp (30%) with stratification\n",
    "train_df, temp_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.3,\n",
    "    stratify=df['species'],  # Stratify based on the 'species' column\n",
    "    random_state=rs\n",
    ")\n",
    "\n",
    "# Split temp into test (15%) and validation (15%)\n",
    "test_df, val_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_df['species'],  # Stratify again to maintain balance\n",
    "    random_state=rs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Training Samples\n",
      "Generating Test Samples\n",
      "Generating Validation Samples\n"
     ]
    }
   ],
   "source": [
    "# Prepare samples\n",
    "print(\"Generating Training Samples\")\n",
    "X_train, y_train, mins_maxes_train, isolated_peaks_train = gen_samples(train_df)\n",
    "print(\"Generating Test Samples\")\n",
    "X_test, y_test, mins_maxes_test, isolated_peaks_test = gen_samples(test_df)\n",
    "print(\"Generating Validation Samples\")\n",
    "X_val, y_val, mins_maxes_val, isolated_peaks_val = gen_samples(val_df)\n",
    "\n",
    "# Restrict to just peak labels (no height/width)\n",
    "y_train=y_train[:, :, 0]\n",
    "y_test=y_test[:, :, 0]\n",
    "y_val=y_val[:, :, 0]\n",
    "\n",
    "M=200\n",
    "y_train=y_train[0:M, :]\n",
    "y_test=y_test[0:M, :]\n",
    "y_val=y_val[0:M, :]\n",
    "\n",
    "X_train=X_train[0:M, :]\n",
    "X_val=X_val[0:M, :]\n",
    "X_test=X_test[0:M, :]\n",
    "\n",
    "# X_train = np.expand_dims(X_train, axis=-1)\n",
    "# X_val = np.expand_dims(X_val, axis=-1)\n",
    "# X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "# y_train = np.expand_dims(y_train, axis=-1)\n",
    "# y_val = np.expand_dims(y_val, axis=-1)\n",
    "# y_test = np.expand_dims(y_test, axis=-1)\n",
    "\n",
    "# Reshape inputs\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Reshape outputs\n",
    "y_train = y_train.reshape(y_train.shape[0], y_train.shape[1], 1)\n",
    "y_val = y_val.reshape(y_val.shape[0], y_val.shape[1], 1)\n",
    "y_test = y_test.reshape(y_test.shape[0], y_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64 (200, 8192, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtype, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 8192\n",
    "M = 200\n",
    "X_train = np.random.rand(M, N, 1)\n",
    "y_train = np.random.randint(0, 2, size=(M, N, 1))\n",
    "X_val = np.random.rand(M, N, 1)\n",
    "y_val = np.random.randint(0, 2, size=(M, N, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters \n",
    "k=3\n",
    "peak_encourage=5\n",
    "include_LSTM=False\n",
    "epochs = 1\n",
    "lr = 0.001\n",
    "model_version = f\"SL_V1_k-{k}_PE-{peak_encourage}_LSTM-{include_LSTM}_Epochs-{epochs}_LR-{lr}\"\n",
    "batch_size = 32\n",
    "patience = 3\n",
    "threshold_list = [0.05, 0.1, 0.15, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SL_V1_k-3_PE-5_LSTM-False_Epochs-1_LR-0.001\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, 8192, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " Conv_3 (Conv1D)                (None, 8192, 4)      16          ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " Conv_5 (Conv1D)                (None, 8192, 8)      48          ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " Conv_9 (Conv1D)                (None, 8192, 16)     160         ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " Conv_15 (Conv1D)               (None, 8192, 32)     512         ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " Conv_31 (Conv1D)               (None, 8192, 32)     1024        ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " Conv_55 (Conv1D)               (None, 8192, 32)     1792        ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " Conv_71 (Conv1D)               (None, 8192, 16)     1152        ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " Conv_101 (Conv1D)              (None, 8192, 8)      816         ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " Conv_149 (Conv1D)              (None, 8192, 4)      600         ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " Conv_201 (Conv1D)              (None, 8192, 2)      404         ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " Inception_Concat (Concatenate)  (None, 8192, 154)   0           ['Conv_3[0][0]',                 \n",
      "                                                                  'Conv_5[0][0]',                 \n",
      "                                                                  'Conv_9[0][0]',                 \n",
      "                                                                  'Conv_15[0][0]',                \n",
      "                                                                  'Conv_31[0][0]',                \n",
      "                                                                  'Conv_55[0][0]',                \n",
      "                                                                  'Conv_71[0][0]',                \n",
      "                                                                  'Conv_101[0][0]',               \n",
      "                                                                  'Conv_149[0][0]',               \n",
      "                                                                  'Conv_201[0][0]']               \n",
      "                                                                                                  \n",
      " Dense_64 (TimeDistributed)     (None, 8192, 64)     9920        ['Inception_Concat[0][0]']       \n",
      "                                                                                                  \n",
      " Dense_32A (TimeDistributed)    (None, 8192, 32)     2080        ['Dense_64[0][0]']               \n",
      "                                                                                                  \n",
      " Dense_32B (TimeDistributed)    (None, 8192, 32)     1056        ['Dense_32A[0][0]']              \n",
      "                                                                                                  \n",
      " Dense_16 (TimeDistributed)     (None, 8192, 16)     528         ['Dense_32B[0][0]']              \n",
      "                                                                                                  \n",
      " Output (TimeDistributed)       (None, 8192, 1)      17          ['Dense_16[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20,125\n",
      "Trainable params: 20,125\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# DEFINE MODEL STRUCTURE\n",
    "# Define the input length / number of frequency bins (N)\n",
    "N = 8192\n",
    "\n",
    "# Input layer\n",
    "input_layer = Input(shape=(N, 1), name=\"Input\")\n",
    "# Inception-like layer with 1D convolutions\n",
    "convs = []\n",
    "# We'll base our kernel choices on the hwhm distribution of the peaks. \n",
    "# Thin peaks are in 3Hz-10Hz range --> 5-15 bins\n",
    "# Wide peaks are in 10Hz-100Hz range --> 15-149 bins\n",
    "# We choose filters at a range of scales, odd (to facilitate being cenetered around a peak)\n",
    "# and we want more filters for the medium-small range since there are more peaks at this scale.\n",
    "# Otherwise largely arbitrarily.\n",
    "kernels = [(3, 4), (5, 8), (9, 16), (15, 32), (31, 32), (55, 32), (71, 16), (101, 8), (149, 4), (201, 2)]\n",
    "for kernel_size, num_filters in kernels:\n",
    "    convs.append(Conv1D(num_filters, kernel_size=kernel_size, activation='relu', padding='same', name=f\"Conv_{kernel_size}\")(input_layer))\n",
    "\n",
    "# Concatenate the outputs199 of all convolutional layers\n",
    "concat_layer = Concatenate(name=\"Inception_Concat\")(convs)\n",
    "\n",
    "# Time Distributed Dense Layers\n",
    "td_dense64 = TimeDistributed(Dense(64, activation='relu'), name=\"Dense_64\")(concat_layer)\n",
    "td_dense32A = TimeDistributed(Dense(32, activation='relu'), name=\"Dense_32A\")(td_dense64)\n",
    "if include_LSTM:\n",
    "    bd_LSTM = Bidirectional(LSTM(16, return_sequences=True), name=\"LSTM\")(td_dense32A)\n",
    "    td_dense32B = TimeDistributed(Dense(32, activation='relu'), name=\"Dense_32B\")(bd_LSTM)\n",
    "else:\n",
    "    td_dense32B = TimeDistributed(Dense(32, activation='relu'), name=\"Dense_32B\")(td_dense32A)\n",
    "td_dense16 = TimeDistributed(Dense(16, activation='relu'), name=\"Dense_16\")(td_dense32B)\n",
    "\n",
    "# Final layer with 3 outputs per input bin\n",
    "output_layer = TimeDistributed(Dense(1, activation='sigmoid'), name=\"Output\")(td_dense16)\n",
    "\n",
    "# Define the model to output both predictions and weights\n",
    "model = tf.keras.Model(\n",
    "    inputs=input_layer, \n",
    "    outputs=output_layer,  # Explicitly define both outputs\n",
    "    name=model_version\n",
    ")\n",
    "\n",
    "\n",
    "# Compile the model (lambda function in loss to allow for prominences to be passed in as weights)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "    loss='binary_crossentropy'\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 10s 1s/step - loss: 0.6933 - val_loss: 0.6932\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time_callback' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 24\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     14\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     15\u001b[0m     x\u001b[38;5;241m=\u001b[39m[X_train],\n\u001b[1;32m     16\u001b[0m     y\u001b[38;5;241m=\u001b[39m[y_train],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m               \u001b[38;5;66;03m# Verbose output\u001b[39;00m\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 24\u001b[0m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch_times\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtime_callback\u001b[49m\u001b[38;5;241m.\u001b[39mepoch_times\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPP Model\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_history.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     27\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(history\u001b[38;5;241m.\u001b[39mhistory, file)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time_callback' is not defined"
     ]
    }
   ],
   "source": [
    "# TRAIN MODEL\n",
    "start_time = time.time()\n",
    "model_path = os.path.join(\"PP Model\", f\"{model_version}.keras\")\n",
    "\n",
    "# Add callbacks for better training\n",
    "callbacks = [\n",
    "    # ValidationMetricCallback(validation_data=(X_val, (y_val, isolated_peaks_val)), metric_name=\"peak_counting_error\"),\n",
    "    # EarlyStopping(monitor=\"peak_counting_error\", patience=patience, restore_best_weights=True, verbose=1),  # Stop if no improvement for 5 epochs\n",
    "    # ModelCheckpoint(model_path, save_best_only=True, monitor='peak_counting_error'),  # Save the best model\n",
    "    ModelCheckpoint(model_path, save_best_only=True, monitor='val_loss'),  # Save the best model\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x=[X_train],\n",
    "    y=[y_train],\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=epochs,        # Number of epochs\n",
    "    batch_size=batch_size,  # Batch size\n",
    "    callbacks=callbacks,    # Add callbacks for early stopping and checkpointing\n",
    "    verbose=1               # Verbose output\n",
    ")\n",
    "\n",
    "history.history['epoch_times'] = time_callback.epoch_times\n",
    "\n",
    "with open(os.path.join(\"PP Model\", f\"{model_version}_history.pkl\"), 'wb') as file:\n",
    "    pickle.dump(history.history, file)\n",
    "    \n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Execution time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(os.path.join(\"PP Model\", f\"{model_version}.keras\"), custom_objects={\"custom_loss\": custom_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the predicted values are probabilities from 0 to 1\n",
    "val_pred = model.predict(X_val)  # Predicted probabilities or binary values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKING PREDICTIONS\n",
    "\n",
    "sample_idx = 10\n",
    "spectrum = X_val[sample_idx, :]\n",
    "# predicted_peaks = val_pred[sample_idx, :, 2] \n",
    "predicted_peaks = val_pred[sample_idx, :]\n",
    "print(val_pred.shape)\n",
    "print(predicted_peaks)\n",
    "\n",
    "\n",
    "# Frequency axis for the spectrum\n",
    "f = rfftfreq(32768, 1/44100)[0:8192]\n",
    "\n",
    "# Plot the spectrum\n",
    "plt.plot(f, spectrum, label='Original Spectrum')\n",
    "\n",
    "# Add colors depending on percentage of prediction\n",
    "scatter = plt.scatter(f, spectrum, c=predicted_peaks, cmap='viridis', s=50)\n",
    "\n",
    "# Add color bar\n",
    "plt.colorbar(scatter, label='Predicted Peaks Value')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Spectrum with Scatter Points Colored by Predicted Peaks Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Mismatch in number of samples!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[246], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_error, best_thresh \u001b[38;5;241m=\u001b[39m \u001b[43mpeak_counting_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43misolated_peaks_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 26\u001b[0m, in \u001b[0;36mpeak_counting_error\u001b[0;34m(isolated_peaks_val, val_predictions)\u001b[0m\n\u001b[1;32m     24\u001b[0m val_predictions \u001b[38;5;241m=\u001b[39m val_predictions[:, :, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     25\u001b[0m M \u001b[38;5;241m=\u001b[39m isolated_peaks_val\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# Number of samples\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m M \u001b[38;5;241m==\u001b[39m val_predictions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch in number of samples!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m best_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m  \u001b[38;5;66;03m# Initial large value for minimizing error\u001b[39;00m\n\u001b[1;32m     28\u001b[0m best_thresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Mismatch in number of samples!"
     ]
    }
   ],
   "source": [
    "best_error, best_thresh = peak_counting_error(isolated_peaks_val, val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 0\n",
    "thresh = best_thresh\n",
    "spectrum = X_val[sample_idx, :]\n",
    "predicted_peaks = val_pred[sample_idx, :] \n",
    "\n",
    "# Frequency axis for the spectrum\n",
    "f = rfftfreq(32768, 1/44100)[0:8192]\n",
    "\n",
    "# Find indices where there are peaks (1 in predicted_peaks)\n",
    "peak_indices = np.where(predicted_peaks > thresh)[0]\n",
    "\n",
    "# Plot the spectrum\n",
    "plt.plot(f, spectrum, label='Original Spectrum')\n",
    "\n",
    "# Plot the peaks as scatter points\n",
    "plt.scatter(f[peak_indices], spectrum[peak_indices], color='red', label='Predicted Peaks')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get validation counting accuracy\n",
    "val_peak_counting_accuracy = peak_counting_accuracy(isolated_peaks_val, val_pred)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKING PEAK LABELS FOR ERRORS\n",
    "\n",
    "sample_idx = 0\n",
    "spectrum = X_train[sample_idx, :]\n",
    "peak_labels = y_train[sample_idx, :, 0]\n",
    "\n",
    "# Frequency axis for the spectrum\n",
    "f = rfftfreq(32768, 1/44100)[0:8192]\n",
    "\n",
    "# Find indices where there are peaks (1 in predicted_peaks)\n",
    "peak_indices = np.where(peak_labels==1)[0]\n",
    "\n",
    "# Plot the spectrum\n",
    "plt.plot(f, spectrum, label='Original Spectrum')\n",
    "\n",
    "# Plot the peaks as scatter points\n",
    "plt.scatter(f[peak_indices], spectrum[peak_indices], color='red', label='Labeled Peaks')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Custom Loss\n",
    "# Example data: batch_size=4, N=5, nodes=3\n",
    "y_true = np.array([\n",
    "    [[0, 0.5, 0.7], [0, 0.2, -1], [0, 10000, -1000], [0, 0.3, 10], [0, 0.1, 10]],  # Sample 1\n",
    "    [[0, 0.6, 0.3], [1, 0.1, -1], [1, 0.3, 10], [0, 0.4, 10], [0, 0.7, 10]],  # Sample 2\n",
    "    [[0, 0.4, 1.5], [1, 0.8, -1], [1, 0.6, 10], [1, 0.2, 10], [0, 0.9, 10]],  # Sample 3\n",
    "    [[0, 0.5, 0.6], [0, 0.3, -1], [0, 0.7, 10], [1, 0.1, 10], [0, 0.8, 10]],  # Sample 4\n",
    "])\n",
    "\n",
    "y_pred = np.array([\n",
    "    [[0.9, 0.6, 0.8], [0.9, 0.3, 0.5], [0.5, 100000, 1000], [0.7, 0.4, 0.6], [0.2, 0.1, 0.3]],  # Sample 1\n",
    "    [[0.7, 0.5, 0.4], [0.9, 0.2, 0.3], [0.9, 0.4, 0.6], [0.6, 0.7, 0.9], [0.8, 0.7, 0.8]],  # Sample 2\n",
    "    [[0.8, 0.4, 0.5], [0.9, 0.6, 0.8], [0.9, 0.7, 0.5], [0.9, 0.3, 0.6], [0.2, 0.9, 0.7]],  # Sample 3\n",
    "    [[0.9, 0.4, 0.3], [0.9, 0.6, 0.8], [0.6, 0.9, 0.7], [0.9, 0.3, 0.5], [0.8, 0.7, 0.6]],  # Sample 4\n",
    "])\n",
    "\n",
    "# Convert to tensors\n",
    "y_true_tensor = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
    "y_pred_tensor = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
    "\n",
    "loss_value = custom_loss(y_true_tensor, y_pred_tensor)\n",
    "print(\"Loss Value:\", loss_value.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a sample\n",
    "i = 1\n",
    "spectrum = X_train[i]\n",
    "f = rfftfreq(32768, 1/44100)[0:8192]\n",
    "\n",
    "labels = y_train[i, :, :]\n",
    "spread_peak_labels = labels[:, 0]\n",
    "indices = np.where(spread_peak_labels == 1)[0]\n",
    "# isolated_peaks = isolated_peaks_train[i]\n",
    "# indices = np.where(isolated_peaks == 1)[0]\n",
    "plt.scatter(f, spectrum, color='blue', s=1)\n",
    "plt.scatter(f[indices], spectrum[indices], color='red', s=1)\n",
    "plt.xlim(3000, 4000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify peak_counting_error\n",
    "isolated_peaks_val=np.array(\n",
    "    [[0, 1, 0, 0, 1], \n",
    "     [1, 0, 1, 0, 0]]\n",
    "    )\n",
    "val_predictions=np.array(\n",
    "    [[0.81, 0.91, 0.71, 0.31, 0.91],\n",
    "     [0.81, 0.21, 0.91, 0.96, 0.91]]\n",
    "    )\n",
    "\n",
    "peak_counting_error(isolated_peaks_val, val_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out how many bins our peaks are\n",
    "f = rfftfreq(32768, 1/44100)\n",
    "# HWFM (in bins) of a peak with a HWHM of 100Hz\n",
    "bin_width = f[1] - f[0]\n",
    "print(f\"HWFM (in bins) of a peak with a HWHM of 100Hz: {200 / bin_width}\")\n",
    "print(f\"HWFM (in bins) of a peak with a HWHM of 10Hz: {20 / bin_width}\")\n",
    "print(f\"HWFM (in bins) of a peak with a HWHM of 3Hz: {6 / bin_width}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_loss(y_true, y_pred):\n",
    "#     \"\"\"\n",
    "#     Custom loss function for (batch_size, N, 3):\n",
    "#     - Binary cross-entropy for the first output node.\n",
    "#     - MSE for the second and third output nodes, masked by the first node's true labels.\n",
    "#     - Each bin in each sample is weighted by f(SNR), where SNR is the 3rd node label.\n",
    "    \n",
    "#     Args:\n",
    "#     y_true: Tensor of true labels, shape (batch_size, N, 3).\n",
    "#     y_pred: Tensor of predicted values, shape (batch_size, N, 3).\n",
    "    \n",
    "#     Returns:\n",
    "#     A scalar tensor representing the combined loss.\n",
    "#     \"\"\"\n",
    "\n",
    "    # # Mean squared error for the second and third nodes\n",
    "    # mse_loss_2 = tf.square(y_true[..., 1] - y_pred[..., 1])\n",
    "    # mse_loss_3 = tf.square(y_true[..., 2] - y_pred[..., 2])\n",
    "    # mse_loss = mse_loss_2 + mse_loss_3  # Shape (batch_size, N)\n",
    "\n",
    "    # # Mask the MSE loss where the first node's true label is 0\n",
    "    # mask = tf.cast(y_true[..., 0] > 0, tf.float32)  # Shape (batch_size, N)\n",
    "    # masked_mse_loss = mse_loss * mask  # Shape (batch_size, N)\n",
    "    \n",
    "    # # Manually calculate binary cross-entropy for the first node\n",
    "    # epsilon = 1e-7  # Small constant to prevent log(0)\n",
    "    # y_pred_clipped = tf.clip_by_value(y_pred[..., 0], epsilon, 1.0 - epsilon)\n",
    "    # bce_loss = -(y_true[..., 0] * tf.math.log(y_pred_clipped) + (1 - y_true[..., 0]) * tf.math.log(1 - y_pred_clipped))  # Shape (batch_size, N)\n",
    "\n",
    "    # # Weighting each bin by weight_func(SNR), where SNR is the 3rd node label\n",
    "    # snr = y_true[..., 2]  # SNR is the 3rd node label, shape (batch_size, N)\n",
    "    # weights = tf.where(snr < 0, tf.ones_like(snr), weight_func(snr))  # If SNR < 0, weight is 1 (fully weight the BCE loss for non-peak bins), else apply weight_func\n",
    "\n",
    "    # # Apply weights to the masked MSE loss\n",
    "    # weighted_mse_loss = masked_mse_loss * weights  # Shape (batch_size, N)\n",
    "    \n",
    "    # # Apply weights to the BCE loss\n",
    "    # weighted_bce_loss = bce_loss * weights  # Shape (batch_size, N)\n",
    "\n",
    "    # # Average weighted MSE, BCE losses across bins (N) for each sample\n",
    "    # mean_mse_loss_per_sample = tf.reduce_mean(weighted_mse_loss, axis=1)  # Mean over N for shape (batch_size,)\n",
    "    # mean_bce_loss_per_sample = tf.reduce_mean(weighted_bce_loss, axis=1)\n",
    "\n",
    "    # # Combine and average across the batch\n",
    "    # total_loss = tf.reduce_mean(mean_bce_loss_per_sample + mean_mse_loss_per_sample)  # Mean over batch size\n",
    "\n",
    "    # return total_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class ValidationMetricCallback(tf.keras.callbacks.Callback):\n",
    "#     def __init__(self, validation_data, metric_name=\"peak_counting_error\"):\n",
    "#         super(ValidationMetricCallback, self).__init__()\n",
    "#         self.validation_data = validation_data\n",
    "#         self.metric_name = metric_name\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         val_x, (val_y, isolated_peaks_val) = self.validation_data  # Unpack extra labels\n",
    "#         val_predictions = self.model.predict(val_x, verbose=0)\n",
    "        \n",
    "#         # Compute your custom metric (e.g., Mean Absolute Error)\n",
    "#         val_metric = peak_counting_error(isolated_peaks_val, val_predictions)\n",
    "\n",
    "#         # Add the validation metric to logs\n",
    "#         logs[self.metric_name] = val_metric.numpy()\n",
    "\n",
    "#         print(f\"Epoch {epoch + 1}: {self.metric_name} = {val_metric.numpy()}\")\n",
    "\n",
    "\n",
    "# for row_idx in range(y_train.shape[0]):\n",
    "#     y_peak_labels = y_train[:, :, 0]\n",
    "#     if tf.reduce_any(y_peak_labels[row_idx] < 0):  # Check if any value in the row is negative\n",
    "#         print(f\"Row {row_idx} contains negative values:\")\n",
    "#         print(y_peak_labels[row_idx])\n",
    "\n",
    "\n",
    "\n",
    "    # # Check for any negative values or values greater than 1 in y_true\n",
    "    # has_negative_y_true = tf.reduce_any(y_true < 0)\n",
    "    # has_greater_one_y_true = tf.reduce_any(y_true > 1)\n",
    "    \n",
    "    # # Check for any negative values in y_pred\n",
    "    # has_negative_y_pred = tf.reduce_any(y_pred < 0)\n",
    "    \n",
    "    # # Use tf.debugging.assert_* to enforce conditions during graph execution\n",
    "    # tf.debugging.assert_equal(\n",
    "    #     has_negative_y_true, False, message=\"y_true contains negative values.\"\n",
    "    # )\n",
    "    # tf.debugging.assert_equal(\n",
    "    #     has_greater_one_y_true, False, message=\"y_true contains values greater than 1.\"\n",
    "    # )\n",
    "    # tf.debugging.assert_equal(\n",
    "    #     has_negative_y_pred, False, message=\"y_pred contains negative values.\"\n",
    "\n",
    "\n",
    "    # # Manually calculate binary cross-entropy for the first node\n",
    "    # epsilon = 1e-7  # Small constant to prevent log(0)\n",
    "    # y_pred_clipped = tf.clip_by_value(y_pred[..., 0], epsilon, 1.0 - epsilon)\n",
    "    # bce_loss = -(y_true[..., 0] * tf.math.log(y_pred_clipped) + (1 - y_true[..., 0]) * tf.math.log(1 - y_pred_clipped))  # Shape (batch_size, N)\n",
    "\n",
    "    # # Weighting each bin by weight_func(prom), where prominence is the 3rd node label\n",
    "    # prom = y_true[..., 2]  # prom is the 3rd node label, shape (batch_size, N)\n",
    "    # weights = tf.where(prom < 0, tf.ones_like(prom), weight_func(snr))  # If prom < 0, weight is 1 (fully weight the BCE loss for non-peak bins), else apply weight_func\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise BCE Loss: [[0.105360404 0.105360404 0.223143399 0.35667479]\n",
      " [0.223143399 0.35667479 0.35667479 0.105360404]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Example data\n",
    "batch_size = 2\n",
    "bins_per_sample = 4\n",
    "\n",
    "y_true = tf.constant([[1, 0, 1, 0], [0, 1, 0, 1]], dtype=tf.float32)  # Shape (batch_size, bins_per_sample)\n",
    "y_pred = tf.constant([[0.9, 0.1, 0.8, 0.3], [0.2, 0.7, 0.3, 0.9]], dtype=tf.float32)  # Shape (batch_size, bins_per_sample)\n",
    "\n",
    "# Compute element-wise binary cross-entropy\n",
    "bce_loss = tf.keras.backend.binary_crossentropy(y_true, y_pred)  # Shape (batch_size, bins_per_sample)\n",
    "\n",
    "# Print the result\n",
    "tf.print(\"Element-wise BCE Loss:\", bce_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M = 100\n",
    "# y_train=y_train[0:M, :]\n",
    "# y_test=y_test[0:M, :]\n",
    "# y_val=y_val[0:M, :]\n",
    "# X_train=X_train[0:M, :]\n",
    "# X_val=X_val[0:M, :]\n",
    "# X_test=X_test[0:M, :]\n",
    "\n",
    "# print(\"TRAIN\")\n",
    "# idx = 1\n",
    "# print(X_train[idx, :])\n",
    "# print(y_train[idx, :])\n",
    "# # Get indices where the value is 1\n",
    "# indices_where_one = np.where(y_train[idx, :] == 1)[0]\n",
    "\n",
    "# # Print the indices\n",
    "# print(\"Indices where the array is 1:\", indices_where_one)\n",
    "\n",
    "# print(\"VAL\")\n",
    "# # Print the selected X_val and y_val row\n",
    "# print(\"X_val row:\", X_val[idx, :])\n",
    "# print(\"y_val row:\", y_val[idx, :])\n",
    "\n",
    "# # Get indices where the value is 1 in the validation labels\n",
    "# indices_where_one_val = np.where(y_val[idx, :] == 1)[0]\n",
    "\n",
    "# # Print the indices\n",
    "# print(\"Indices where the array is 1:\", indices_where_one_val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter [/fs/ess/PAS2038/PHYSICS_5680_OSU/jupyter/]",
   "language": "python",
   "name": "venv_jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
